{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NER_release.ipynb","provenance":[{"file_id":"1rY49V2cp0PLnEgdlwiQhMEwgkBuBVjmz","timestamp":1614403777453},{"file_id":"1G7eSba0a66l29zvyldukPv-aNfpEbe-z","timestamp":1613535091507}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"2fd08084e2014bfe8f48d26fc6c4fd71":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3b31a2ade5e541ffac182dcdbe519131","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7af115de69dc4113bdaa9f12d7bd0ff6","IPY_MODEL_d3a7830219c847a5acbf3ddbaff25011"]}},"3b31a2ade5e541ffac182dcdbe519131":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7af115de69dc4113bdaa9f12d7bd0ff6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_560984a704994bffaa7e4cefcdd5dc5a","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"","max":1499,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1499,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_78248c94ac3d40c7bb738de5553f21b3"}},"d3a7830219c847a5acbf3ddbaff25011":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6b3244de5db147db89b25394ee0db635","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1499/1499 [00:25&lt;00:00, 58.68it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7a23a92b6e694bc9aaf44cc02b198391"}},"560984a704994bffaa7e4cefcdd5dc5a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"78248c94ac3d40c7bb738de5553f21b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6b3244de5db147db89b25394ee0db635":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7a23a92b6e694bc9aaf44cc02b198391":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"192b8a20fc69404ab4f99f2830b384d9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8ae4a4c9716240f38f714f3a04bffbab","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_76654caae69f4b59b8a5a73a6c0d6a96","IPY_MODEL_961b7752ad2049eb9a25acb03db02fe2"]}},"8ae4a4c9716240f38f714f3a04bffbab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"76654caae69f4b59b8a5a73a6c0d6a96":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a0cdd78ef8f146c79b1bcb65d73023e5","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"","max":1499,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1499,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ae43ea1370464518bd52fb9478e02452"}},"961b7752ad2049eb9a25acb03db02fe2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_067c99c2b2f7498e82f5fdde5bc03325","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1499/1499 [00:25&lt;00:00, 60.88it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_17d4c45e9682478694fdc654393ddc4f"}},"a0cdd78ef8f146c79b1bcb65d73023e5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ae43ea1370464518bd52fb9478e02452":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"067c99c2b2f7498e82f5fdde5bc03325":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"17d4c45e9682478694fdc654393ddc4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e72756bee8c0441fb24c1b44297c068d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_27af77b5f9c94eb08ae6460283e8aad1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7a5762d3f169434496118c3a9bb45440","IPY_MODEL_cc8e90c20b284c85b426fbad041a55c6"]}},"27af77b5f9c94eb08ae6460283e8aad1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7a5762d3f169434496118c3a9bb45440":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_16b113e40d7e4b508767883fd9f53c10","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"","max":1499,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1499,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b0ee064d5430443a94167a1468514d70"}},"cc8e90c20b284c85b426fbad041a55c6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_13c1604427944b4aba62ac76fa65703d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1499/1499 [00:25&lt;00:00, 58.42it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1b54889cc4aa4b9ca1c6ff2693b57d44"}},"16b113e40d7e4b508767883fd9f53c10":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b0ee064d5430443a94167a1468514d70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"13c1604427944b4aba62ac76fa65703d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1b54889cc4aa4b9ca1c6ff2693b57d44":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5c21c8bd50c24a33ae8171eec6d1badc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_257829f5609d4255bd4ab58620cd1ef3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_796be385795741a58f8482ad419f9afa","IPY_MODEL_46ea688cb0554d599aaee803836f1376"]}},"257829f5609d4255bd4ab58620cd1ef3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"796be385795741a58f8482ad419f9afa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a58cf591050c454cadeeee5426fa5a8c","_dom_classes":[],"description":" 23%","_model_name":"FloatProgressModel","bar_style":"danger","max":1499,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":344,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1c3e5f67ee8547818a411b22a754eedb"}},"46ea688cb0554d599aaee803836f1376":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5418c4a5391a4eed8c67f29d5ab909c7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 344/1499 [00:20&lt;00:21, 54.38it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3dff3f5ac79d48ca88e283bc263d00cb"}},"a58cf591050c454cadeeee5426fa5a8c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1c3e5f67ee8547818a411b22a754eedb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5418c4a5391a4eed8c67f29d5ab909c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3dff3f5ac79d48ca88e283bc263d00cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d68e63144cf745f6a4d88c761ccfa0d7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_064cfc3ee5924fb6b0c03ce565d1c5eb","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5ee64e4e1fe64667912fd82ade65cce8","IPY_MODEL_599dc48752784337b635aadc0679c9dd"]}},"064cfc3ee5924fb6b0c03ce565d1c5eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5ee64e4e1fe64667912fd82ade65cce8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1bab511fba9e4f26a486aef195fec324","_dom_classes":[],"description":"  8%","_model_name":"FloatProgressModel","bar_style":"danger","max":1499,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":123,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_82cb79d9af514a9d8581aa7407444bcf"}},"599dc48752784337b635aadc0679c9dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_19d570e282da482ab05391648bbbe672","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 123/1499 [00:15&lt;00:27, 49.81it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f2b727b7759c4a10b61522d204e259b1"}},"1bab511fba9e4f26a486aef195fec324":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"82cb79d9af514a9d8581aa7407444bcf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"19d570e282da482ab05391648bbbe672":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f2b727b7759c4a10b61522d204e259b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d170908978cf4c96aac39f19644f2971":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_592a68199d754ee49d500ea7a87b53e3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_02bbabf4502948a0b783f63761488517","IPY_MODEL_aa98f8019b794bce9a2bbf5345126d65"]}},"592a68199d754ee49d500ea7a87b53e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"02bbabf4502948a0b783f63761488517":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_75602845b9b6478c8c996e7d3a63f167","_dom_classes":[],"description":" 45%","_model_name":"FloatProgressModel","bar_style":"","max":1499,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":673,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_72252639fbbf42728128f715367fd447"}},"aa98f8019b794bce9a2bbf5345126d65":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b7f39b1853f4477ba73fd8a2e8ee24d1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 673/1499 [06:01&lt;07:55,  1.74it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ba7810efaa5348f0b7a4c03cb8cf0e9c"}},"75602845b9b6478c8c996e7d3a63f167":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"72252639fbbf42728128f715367fd447":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b7f39b1853f4477ba73fd8a2e8ee24d1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ba7810efaa5348f0b7a4c03cb8cf0e9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"yj21IyLWKoxk"},"source":["# Licensing Information:  You are free to use or extend this project for\n","# educational purposes provided that (1) you do not distribute or publish\n","# solutions, (2) you retain this notice, and (3) you provide clear\n","# attribution to The Georgia Institute of Technology, including a link to https://aritter.github.io/CS-7650/\n","\n","# Attribution Information: This assignment was developed at The Georgia Institute of Technology\n","# by Alan Ritter (alan.ritter@cc.gatech.edu)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2U5ZbrBGbFes"},"source":["# Project #2: Named Entity Recognition\n","\n","In this assignment, you will implement a bidirectional LSTM-CNN-CRF for sequence labeling, following [this paper by Xuezhe Ma and Ed Hovy](https://www.aclweb.org/anthology/P16-1101.pdf), on the CoNLL named entity recognition dataset.  Before starting the assignment, we recommend reading the Ma and Hovy paper.\n","\n","First, let's import some libraries and make sure the runtime has access to a GPU.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IJdlwzlqq0LI","executionInfo":{"status":"ok","timestamp":1616003824619,"user_tz":240,"elapsed":4092,"user":{"displayName":"Collin Avidano","photoUrl":"","userId":"00144222138809176447"}},"outputId":"b5ec1d17-8fce-41b7-b19d-6a207d9f0b1a"},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)\n","\n","print(f'GPU available: {torch.cuda.is_available()}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Wed Mar 17 17:57:04 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.56       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","GPU available: True\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"q6uw-MGrpEOb"},"source":["## Download the Data\n","\n","Run the following code to download the English part of the CoNLL 2003 dataset, the evaluation script and pre-filtered GloVe embeddings we are providing for this data."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YIzJzPU0p7e4","executionInfo":{"status":"ok","timestamp":1616003834401,"user_tz":240,"elapsed":7987,"user":{"displayName":"Collin Avidano","photoUrl":"","userId":"00144222138809176447"}},"outputId":"ee02c527-0bc6-4cdf-d161-4ccae0a2300b"},"source":["#CoNLL 2003 data\n","!wget https://raw.githubusercontent.com/patverga/torch-ner-nlp-from-scratch/master/data/conll2003/eng.train\n","!wget https://raw.githubusercontent.com/patverga/torch-ner-nlp-from-scratch/master/data/conll2003/eng.testa\n","!wget https://raw.githubusercontent.com/patverga/torch-ner-nlp-from-scratch/master/data/conll2003/eng.testb\n","!cat eng.train | awk '{print $1 \"\\t\" $4}' > train\n","!cat eng.testa | awk '{print $1 \"\\t\" $4}' > dev\n","!cat eng.testb | awk '{print $1 \"\\t\" $4}' > test\n","\n","#Evaluation Script\n","!wget https://raw.githubusercontent.com/aritter/twitter_nlp/master/data/annotated/wnut16/conlleval.pl\n","\n","#Pre-filtered GloVe embeddings\n","!wget https://raw.githubusercontent.com/aritter/aritter.github.io/master/files/glove.840B.300d.conll_filtered.txt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2021-03-17 17:57:06--  https://raw.githubusercontent.com/patverga/torch-ner-nlp-from-scratch/master/data/conll2003/eng.train\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 3283420 (3.1M) [text/plain]\n","Saving to: ‘eng.train’\n","\n","eng.train           100%[===================>]   3.13M  --.-KB/s    in 0.1s    \n","\n","2021-03-17 17:57:07 (21.7 MB/s) - ‘eng.train’ saved [3283420/3283420]\n","\n","--2021-03-17 17:57:07--  https://raw.githubusercontent.com/patverga/torch-ner-nlp-from-scratch/master/data/conll2003/eng.testa\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 827443 (808K) [text/plain]\n","Saving to: ‘eng.testa’\n","\n","eng.testa           100%[===================>] 808.05K  --.-KB/s    in 0.07s   \n","\n","2021-03-17 17:57:08 (11.9 MB/s) - ‘eng.testa’ saved [827443/827443]\n","\n","--2021-03-17 17:57:08--  https://raw.githubusercontent.com/patverga/torch-ner-nlp-from-scratch/master/data/conll2003/eng.testb\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 748095 (731K) [text/plain]\n","Saving to: ‘eng.testb’\n","\n","eng.testb           100%[===================>] 730.56K  --.-KB/s    in 0.06s   \n","\n","2021-03-17 17:57:08 (12.6 MB/s) - ‘eng.testb’ saved [748095/748095]\n","\n","--2021-03-17 17:57:08--  https://raw.githubusercontent.com/aritter/twitter_nlp/master/data/annotated/wnut16/conlleval.pl\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 12754 (12K) [text/plain]\n","Saving to: ‘conlleval.pl’\n","\n","conlleval.pl        100%[===================>]  12.46K  --.-KB/s    in 0s      \n","\n","2021-03-17 17:57:09 (93.1 MB/s) - ‘conlleval.pl’ saved [12754/12754]\n","\n","--2021-03-17 17:57:09--  https://raw.githubusercontent.com/aritter/aritter.github.io/master/files/glove.840B.300d.conll_filtered.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 69798443 (67M) [text/plain]\n","Saving to: ‘glove.840B.300d.conll_filtered.txt’\n","\n","glove.840B.300d.con 100%[===================>]  66.56M   112MB/s    in 0.6s    \n","\n","2021-03-17 17:57:14 (112 MB/s) - ‘glove.840B.300d.conll_filtered.txt’ saved [69798443/69798443]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mv5CEGkGp3w1"},"source":["## CoNLL Data Format\n","\n","Run the following cell to see a sample of the data in CoNLL format.  As you can see, each line in the file represents a word and its labeled named entity tag in BIO format.  A blank line is used to seperate sentences."]},{"cell_type":"code","metadata":{"id":"nbSvvi3Jtb4g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616003835771,"user_tz":240,"elapsed":489,"user":{"displayName":"Collin Avidano","photoUrl":"","userId":"00144222138809176447"}},"outputId":"7c3fb4c5-66ce-404c-d54e-15f56d6c2ff9"},"source":["!head -n 20 train"],"execution_count":null,"outputs":[{"output_type":"stream","text":["-DOCSTART-\tO\n","\t\n","EU\tI-ORG\n","rejects\tO\n","German\tI-MISC\n","call\tO\n","to\tO\n","boycott\tO\n","British\tI-MISC\n","lamb\tO\n",".\tO\n","\t\n","Peter\tI-PER\n","Blackburn\tI-PER\n","\t\n","BRUSSELS\tI-LOC\n","1996-08-22\tO\n","\t\n","The\tO\n","European\tI-ORG\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XM9F617sqbvc"},"source":["## Reading in the Data\n","\n","Below we proivide a bit of code to read in data in the CoNLL format.  This also reads in the filtered GloVe embeddings, to save you some effort - we will discuss this more later."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tQ4lnZuoqisy","executionInfo":{"status":"ok","timestamp":1616003840527,"user_tz":240,"elapsed":3318,"user":{"displayName":"Collin Avidano","photoUrl":"","userId":"00144222138809176447"}},"outputId":"e026f22c-7a88-4078-a830-94123ec84c23"},"source":["import re\n","\n","#Read in the training data.\n","def read_conll_format(filename):\n","  (words, tags, currentSent, currentTags) = ([],[],['-START-'],['START'])\n","  for line in open(filename).readlines():\n","    line = line.strip()\n","    #print(line)\n","    if line == \"\":\n","      currentSent.append('-END-')\n","      currentTags.append('END')\n","      words.append(currentSent)\n","      tags.append(currentTags)\n","      (currentSent, currentTags) = (['-START-'], ['START'])\n","    else:\n","      (word, tag) = line.split()\n","      currentSent.append(word)\n","      currentTags.append(tag)\n","  return (words, tags)\n","\n","#Read GloVe embeddings.\n","def read_GloVe(filename):\n","  embeddings = {}\n","  for line in open(filename).readlines():\n","    #print(line)\n","    fields = line.strip().split(\" \")\n","    word = fields[0]\n","    embeddings[word] = [float(x) for x in fields[1:]]\n","  return embeddings\n","\n","GloVe = read_GloVe(\"glove.840B.300d.conll_filtered.txt\")\n","\n","(sentences_train, tags_train) = read_conll_format(\"train\")\n","(sentences_dev, tags_dev)     = read_conll_format(\"dev\")\n","\n","def sentences2char(sentences):\n","  return [[['start'] + [c for c in w] + ['end'] for w in l] for l in sentences]\n","\n","sentencesChar = sentences2char(sentences_train)\n","\n","print(sentences_train[2])\n","print(tags_train[2])\n","\n","print(GloVe['the'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['-START-', 'Peter', 'Blackburn', '-END-']\n","['START', 'I-PER', 'I-PER', 'END']\n","[0.27204, -0.06203, -0.1884, 0.023225, -0.018158, 0.0067192, -0.13877, 0.17708, 0.17709, 2.5882, -0.35179, -0.17312, 0.43285, -0.10708, 0.15006, -0.19982, -0.19093, 1.1871, -0.16207, -0.23538, 0.003664, -0.19156, -0.085662, 0.039199, -0.066449, -0.04209, -0.19122, 0.011679, -0.37138, 0.21886, 0.0011423, 0.4319, -0.14205, 0.38059, 0.30654, 0.020167, -0.18316, -0.0065186, -0.0080549, -0.12063, 0.027507, 0.29839, -0.22896, -0.22882, 0.14671, -0.076301, -0.1268, -0.0066651, -0.052795, 0.14258, 0.1561, 0.05551, -0.16149, 0.09629, -0.076533, -0.049971, -0.010195, -0.047641, -0.16679, -0.2394, 0.0050141, -0.049175, 0.013338, 0.41923, -0.10104, 0.015111, -0.077706, -0.13471, 0.119, 0.10802, 0.21061, -0.051904, 0.18527, 0.17856, 0.041293, -0.014385, -0.082567, -0.035483, -0.076173, -0.045367, 0.089281, 0.33672, -0.22099, -0.0067275, 0.23983, -0.23147, -0.88592, 0.091297, -0.012123, 0.013233, -0.25799, -0.02972, 0.016754, 0.01369, 0.32377, 0.039546, 0.042114, -0.088243, 0.30318, 0.087747, 0.16346, -0.40485, -0.043845, -0.040697, 0.20936, -0.77795, 0.2997, 0.2334, 0.14891, -0.39037, -0.053086, 0.062922, 0.065663, -0.13906, 0.094193, 0.10344, -0.2797, 0.28905, -0.32161, 0.020687, 0.063254, -0.23257, -0.4352, -0.017049, -0.32744, -0.047064, -0.075149, -0.18788, -0.015017, 0.029342, -0.3527, -0.044278, -0.13507, -0.11644, -0.1043, 0.1392, 0.0039199, 0.37603, 0.067217, -0.37992, -1.1241, -0.057357, -0.16826, 0.03941, 0.2604, -0.023866, 0.17963, 0.13553, 0.2139, 0.052633, -0.25033, -0.11307, 0.22234, 0.066597, -0.11161, 0.062438, -0.27972, 0.19878, -0.36262, -1.0006e-05, -0.17262, 0.29166, -0.15723, 0.054295, 0.06101, -0.39165, 0.2766, 0.057816, 0.39709, 0.025229, 0.24672, -0.08905, 0.15683, -0.2096, -0.22196, 0.052394, -0.01136, 0.050417, -0.14023, -0.042825, -0.031931, -0.21336, -0.20402, -0.23272, 0.07449, 0.088202, -0.11063, -0.33526, -0.014028, -0.29429, -0.086911, -0.1321, -0.43616, 0.20513, 0.0079362, 0.48505, 0.064237, 0.14261, -0.43711, 0.12783, -0.13111, 0.24673, -0.27496, 0.15896, 0.43314, 0.090286, 0.24662, 0.066463, -0.20099, 0.1101, 0.03644, 0.17359, -0.15689, -0.086328, -0.17316, 0.36975, -0.40317, -0.064814, -0.034166, -0.013773, 0.062854, -0.17183, -0.12366, -0.034663, -0.22793, -0.23172, 0.239, 0.27473, 0.15332, 0.10661, -0.060982, -0.024805, -0.13478, 0.17932, -0.37374, -0.02893, -0.11142, -0.08389, -0.055932, 0.068039, -0.10783, 0.1465, 0.094617, -0.084554, 0.067429, -0.3291, 0.034082, -0.16747, -0.25997, -0.22917, 0.020159, -0.02758, 0.16136, -0.18538, 0.037665, 0.57603, 0.20684, 0.27941, 0.16477, -0.018769, 0.12062, 0.069648, 0.059022, -0.23154, 0.24095, -0.3471, 0.04854, -0.056502, 0.41566, -0.43194, 0.4823, -0.051759, -0.27285, -0.25893, 0.16555, -0.1831, -0.06734, 0.42457, 0.010346, 0.14237, 0.25939, 0.17123, -0.13821, -0.066846, 0.015981, -0.30193, 0.043579, -0.043102, 0.35025, -0.19681, -0.4281, 0.16899, 0.22511, -0.28557, -0.1028, -0.018168, 0.11407, 0.13015, -0.18317, 0.1323]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6zeg1gSiqyLD"},"source":["## Mapping Tokens to Indices\n","\n","# As in the last project, we will need to convert words in the dataset to numeric indices, so they can be presented as input to a neural network.  Code to handle this for you with sample usage is provided below."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"99p1PPX5qlPQ","executionInfo":{"status":"ok","timestamp":1616003844810,"user_tz":240,"elapsed":1615,"user":{"displayName":"Collin Avidano","photoUrl":"","userId":"00144222138809176447"}},"outputId":"5a90ea65-c3de-4f7c-eb5b-358014d41f6b"},"source":["#Create mappings between tokens and indices.\n","\n","from collections import Counter\n","import random\n","\n","#Will need this later to remove 50% of words that only appear once in the training data from the vocabulary (and don't have GloVe embeddings).\n","wordCounts = Counter([w for l in sentences_train for w in l])\n","charCounts = Counter([c for l in sentences_train for w in l for c in w])\n","singletons = set([w for (w,c) in wordCounts.items() if c == 1 and not w in GloVe.keys()])\n","charSingletons = set([w for (w,c) in charCounts.items() if c == 1])\n","\n","#Build dictionaries to map from words, characters to indices and vice versa.\n","#Save first two words in the vocabulary for padding and \"UNK\" token.\n","word2i = {w:i+2 for i,w in enumerate(set([w for l in sentences_train for w in l] + list(GloVe.keys())))}\n","char2i = {w:i+2 for i,w in enumerate(set([c for l in sentencesChar for w in l for c in w]))}\n","i2word = {i:w for w,i in word2i.items()}\n","i2char  = {i:w for w,i in char2i.items()}\n","\n","#Tag dictionaries.\n","tag2i = {w:i for i,w in enumerate(set([t for l in tags_train for t in l]))}\n","i2tag = {i:t for t,i in tag2i.items()}\n","\n","#When training, randomly replace singletons with UNK tokens sometimes to simulate situation at test time.\n","def getDictionaryRandomUnk(w, dictionary, train=False):\n","  if train and (w in singletons and random.random() > 0.5):\n","    return 1\n","  else:\n","    return dictionary.get(w, 1)\n","\n","#Map a list of sentences from words to indices.\n","def sentences2indices(words, dictionary, train=False):\n","  #1.0 => UNK\n","  return [[getDictionaryRandomUnk(w,dictionary, train=train) for w in l] for l in words]\n","\n","#Map a list of sentences containing to indices (character indices)\n","def sentences2indicesChar(chars, dictionary):\n","  #1.0 => UNK\n","  return [[[dictionary.get(c,1) for c in w] for w in l] for l in chars]\n","\n","#Indices\n","X       = sentences2indices(sentences_train, word2i, train=True)\n","X_char  = sentences2indicesChar(sentencesChar, char2i)\n","Y       = sentences2indices(tags_train, tag2i)\n","\n","print(i2word[253])\n","\n","#Print out some examples of what the dev inputs will look like\n","for i in range(10):\n","  print(\" \".join([i2word.get(w,'UNK') for w in X[i]]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cito\n","-START- -DOCSTART- -END-\n","-START- EU rejects German call to boycott British lamb . -END-\n","-START- Peter Blackburn -END-\n","-START- BRUSSELS 1996-08-22 -END-\n","-START- The European Commission said on Thursday it disagreed with German advice to consumers to shun British lamb until scientists determine whether mad cow disease can be transmitted to sheep . -END-\n","-START- Germany 's representative to the European Union 's veterinary committee Werner Zwingmann said on Wednesday consumers should buy sheepmeat from countries other than Britain until the scientific advice was clearer . -END-\n","-START- \" We do n't support any such recommendation because we do n't see any grounds for it , \" the Commission 's chief spokesman Nikolaus van der Pas told a news briefing . -END-\n","-START- He said further scientific study was required and if it was found that action was needed it should be taken by the European Union . -END-\n","-START- He said a proposal last month by EU Farm Commissioner Franz Fischler to ban sheep brains , spleens and spinal cords from the human and animal food chains was a highly specific and precautionary move to protect human health . -END-\n","-START- Fischler proposed EU-wide measures after reports from Britain and France that under laboratory conditions sheep could contract Bovine Spongiform Encephalopathy ( BSE ) -- mad cow disease . -END-\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lHGxN6QCr3GY"},"source":["## Padding and Batching\n","\n","In this assignment, you should train your models using minibatched SGD, rather than using a batch size of 1 as we did in the previous project.  When presenting multiple sentences to the network at the same time, we will need to pad them to be of the same length.\n","\n","Below we provide some code to prepare batches of data to present to the network.  \n","\n","**Side Note:** PyTorch includes utilities in [`torch.utils.data`](https://pytorch.org/docs/stable/data.html) to help with padding, batching, shuffling and some other things, but for this assignment we will do everything from scratch to help you see exactly how this works."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZHuYuoSYmgiC","executionInfo":{"status":"ok","timestamp":1616003855864,"user_tz":240,"elapsed":8876,"user":{"displayName":"Collin Avidano","photoUrl":"","userId":"00144222138809176447"}},"outputId":"e8e95b92-c9bd-4a4a-b86d-4edf1f293479"},"source":["#Pad inputs to max sequence length (for batching)\n","def prepare_input(X_list):\n","  X_padded = torch.nn.utils.rnn.pad_sequence([torch.as_tensor(l) for l in X_list], batch_first=True).type(torch.LongTensor)\n","  X_mask   = torch.nn.utils.rnn.pad_sequence([torch.as_tensor([1.0] * len(l)) for l in X_list], batch_first=True).type(torch.FloatTensor)\n","  return (X_padded, X_mask)\n","\n","#Maximum word length (for character representations)\n","MAX_CLEN=32\n","\n","def prepare_input_char(X_list):\n","  MAX_SLEN = max([len(l) for l in X_list])\n","  X_padded  = [l + [[]]*(MAX_SLEN-len(l))  for l in X_list]\n","  X_padded  = [[w[0:MAX_CLEN] for w in l] for l in X_padded]\n","  X_padded  = [[w + [1]*(MAX_CLEN-len(w)) for w in l] for l in X_padded]\n","  #X_mask    = [[1]*len(l) + [0]*(MAX_SLEN-len(l)) for l in X_list]\n","  return torch.as_tensor(X_padded).type(torch.LongTensor)\n","\n","#Pad outputs using one-hot encoding\n","def prepare_output_onehot(Y_list, NUM_TAGS=max(tag2i.values())+1):\n","  Y_onehot = [torch.zeros(len(l), NUM_TAGS) for l in Y_list]\n","  for i in range(len(Y_list)):\n","   for j in range(len(Y_list[i])):\n","    Y_onehot[i][j,Y_list[i][j]] = 1.0\n","  Y_padded = torch.nn.utils.rnn.pad_sequence(Y_onehot, batch_first=True).type(torch.FloatTensor)\n","  return Y_padded\n","\n","print(\"max slen:\", max([len(x) for x in X_char]))  #Max sequence length in the training data is 39.\n","\n","(X_padded, X_mask) = prepare_input(X)\n","X_padded_char = prepare_input_char(X_char)\n","Y_onehot = prepare_output_onehot(Y)\n","\n","print(\"X_padded:\", X_padded.shape)\n","print(\"X_padded_char:\", X_padded_char.shape)\n","print(\"Y_onehot:\", Y_onehot.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["max slen: 115\n","X_padded: torch.Size([14987, 115])\n","X_padded_char: torch.Size([14987, 115, 32])\n","Y_onehot: torch.Size([14987, 115, 10])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MSynCsJzu717"},"source":["## **Your code starts here:** Basic LSTM Tagger (10 points)\n","\n","OK, now you should have everything you need to get started.\n","\n","Recall that your goal is to to implement the BiLSTM-CNN-CRF, as described in [(Ma and Hovy, 2016)](https://www.aclweb.org/anthology/P16-1101.pdf).  This is a relatively complex network with various components.  Below we provide starter code to break down your implementation into increasingly complex versions of the final model, starting with a Basic LSTM tagger.  This way you can be confident that each part is working correctly before incrementally increasing the complexity of your implementation.  This is generally a good approach to take when implementing complex models, since buggy PyTorch code is often partially working, but produces worse results than a correct implementation, so it's hard to know whether added complexities are helping or hurting.  Also, if you aren't able to match published results it's hard to know which component of your model has the problem (or even whether or not it is a problem in the published result!)\n","\n","Fill in the functions marked as `TODO` in the code block below.  If everything is working correctly, you should be able to achieve an F1 score of 0.87 on the dev set and 0.83 on the test set (with GloVe embeddings)."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bl5EsH2WgxLh","executionInfo":{"status":"ok","timestamp":1616004108423,"user_tz":240,"elapsed":750,"user":{"displayName":"Collin Avidano","photoUrl":"","userId":"00144222138809176447"}},"outputId":"4b1adccb-c778-4c72-8683-58e9a8b3de04"},"source":["class BasicLSTMtagger(nn.Module):\n","    def __init__(self, DIM_EMB=10, DIM_HID=10):\n","        super(BasicLSTMtagger, self).__init__()\n","        NUM_TAGS = max(tag2i.values())+1\n","\n","        print(len(word2i))\n","        print(MAX_CLEN)\n","        (self.DIM_EMB, self.NUM_TAGS) = (DIM_EMB, NUM_TAGS)\n","        #TODO: initialize parameters - embedding layer, nn.LSTM, nn.Linear and nn.LogSoftmax\n","        #CHECK THIS\n","        # self.embed = nn.Embedding(len(word2i) + 2, DIM_EMB)\n","        self.init_glove(GloVe)\n","        self.drop = torch.nn.Dropout(p=0.5)\n","        self.lstm = nn.LSTM(DIM_EMB, DIM_HID, batch_first=True, dropout=0.5, bidirectional=True)\n","        self.fc = nn.Linear(DIM_HID*2, NUM_TAGS)\n","        self.softmax = nn.LogSoftmax(dim=2)\n","        # only arg to this is which dimension to compute the softmax along\n","\n","    def forward(self, X, train=False):\n","        #TODO: Implement the forward computation.\n","        embeddings = self.embed(X)\n","        # print(\"embeddings.shape\",embeddings.shape)\n","        x = self.drop(embeddings)\n","        out, hidden = self.lstm(x)\n","        tag_scores = self.fc(out)\n","        tag_probs = self.softmax(tag_scores)\n","        return tag_probs\n","\n","    def init_glove(self, GloVe):\n","      #TODO: initialize word embeddings using GloVe (you can skip this part in your first version, if you want, see instructions below).\n","      glove_pretrain = torch.rand([len(word2i) + 2, self.DIM_EMB])\n","      for item in GloVe.items():\n","        glove_pretrain[word2i.get(item[0], 1), :] = torch.FloatTensor(item[1])\n","\n","      self.embed = nn.Embedding.from_pretrained(glove_pretrain, freeze = False)\n","      \n","\n","    def inference(self, sentences):\n","      X = prepare_input(sentences2indices(sentences, word2i))[0].cuda()\n","      pred = self.forward(X).argmax(dim=2)\n","      return [[i2tag[pred[i,j].item()] for j in range(len(sentences[i]))] for i in range(len(sentences))]\n","\n","    def print_predictions(self, words, tags):\n","      Y_pred = self.inference(words)\n","      for i in range(len(words)):\n","        print(\"----------------------------\")\n","        print(\" \".join([f\"{words[i][j]}/{Y_pred[i][j]}/{tags[i][j]}\" for j in range(len(words[i]))]))\n","        print(\"Predicted:\\t\", Y_pred[i])\n","        print(\"Gold:\\t\\t\", tags[i])\n","\n","    def write_predictions(self, sentences, outFile):\n","      fOut = open(outFile, 'w')\n","      for s in sentences:\n","        y = self.inference([s])[0]\n","        #print(\"\\n\".join(y[1:len(y)-1]))\n","        fOut.write(\"\\n\".join(y[1:len(y)-1]))  #Skip start and end tokens\n","        fOut.write(\"\\n\\n\")\n","\n","#The following code will initialize a model and test that your forward computation runs without errors.\n","lstm        = BasicLSTMtagger(DIM_HID=7, DIM_EMB=300)\n","lstm_output = lstm.forward(prepare_input(X[0:5])[0])\n","Y_onehot    = prepare_output_onehot(Y[0:5])\n","\n","#Check the shape of the lstm_output and one-hot label tensors.\n","print(\"lstm output shape:\", lstm_output.shape)\n","print(\"Y onehot shape:\", Y_onehot.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["29146\n","32\n","lstm output shape: torch.Size([5, 32, 10])\n","Y onehot shape: torch.Size([5, 32, 10])\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:63: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"99ZVaS50gyGY"},"source":["#Read in the data\n","\n","(sentences_dev, tags_dev)     = read_conll_format('dev')\n","(sentences_train, tags_train) = read_conll_format('train')\n","(sentences_test, tags_test)   = read_conll_format('test')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F7Xbox3alX0b"},"source":["# Train your Model (10 points)\n","\n","Next, implement the function below to train your basic BiLSTM tagger.  See [torch.nn.lstm](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html).  Make sure to save your predictions on the test set (`test_pred_lstm.txt`) for submission to GradeScope."]},{"cell_type":"code","metadata":{"id":"PvJyLIjR6HjT","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["2fd08084e2014bfe8f48d26fc6c4fd71","3b31a2ade5e541ffac182dcdbe519131","7af115de69dc4113bdaa9f12d7bd0ff6","d3a7830219c847a5acbf3ddbaff25011","560984a704994bffaa7e4cefcdd5dc5a","78248c94ac3d40c7bb738de5553f21b3","6b3244de5db147db89b25394ee0db635","7a23a92b6e694bc9aaf44cc02b198391","192b8a20fc69404ab4f99f2830b384d9","8ae4a4c9716240f38f714f3a04bffbab","76654caae69f4b59b8a5a73a6c0d6a96","961b7752ad2049eb9a25acb03db02fe2","a0cdd78ef8f146c79b1bcb65d73023e5","ae43ea1370464518bd52fb9478e02452","067c99c2b2f7498e82f5fdde5bc03325","17d4c45e9682478694fdc654393ddc4f","e72756bee8c0441fb24c1b44297c068d","27af77b5f9c94eb08ae6460283e8aad1","7a5762d3f169434496118c3a9bb45440","cc8e90c20b284c85b426fbad041a55c6","16b113e40d7e4b508767883fd9f53c10","b0ee064d5430443a94167a1468514d70","13c1604427944b4aba62ac76fa65703d","1b54889cc4aa4b9ca1c6ff2693b57d44","5c21c8bd50c24a33ae8171eec6d1badc","257829f5609d4255bd4ab58620cd1ef3","796be385795741a58f8482ad419f9afa","46ea688cb0554d599aaee803836f1376","a58cf591050c454cadeeee5426fa5a8c","1c3e5f67ee8547818a411b22a754eedb","5418c4a5391a4eed8c67f29d5ab909c7","3dff3f5ac79d48ca88e283bc263d00cb"]},"executionInfo":{"status":"error","timestamp":1616004220577,"user_tz":240,"elapsed":107822,"user":{"displayName":"Collin Avidano","photoUrl":"","userId":"00144222138809176447"}},"outputId":"20ffe143-c4fd-42fe-99cb-353e33638e73"},"source":["#Training\n","\n","from random import sample\n","import tqdm\n","import os\n","import subprocess\n","import random\n","\n","def shuffle_sentences(sentences, tags):\n","  shuffled_sentences = []\n","  shuffled_tags      = []\n","  indices = list(range(len(sentences)))\n","  random.shuffle(indices)\n","  for i in indices:\n","    #print(len(sentences[i]), len(tags[i]))\n","    shuffled_sentences.append(sentences[i])\n","    shuffled_tags.append(tags[i])\n","  return (shuffled_sentences, shuffled_tags)\n","\n","nEpochs = 10\n","\n","def train_basic_lstm(sentences, tags, lstm):\n","  optimizer = optim.Adadelta(lstm.parameters(), lr=0.1)\n","\n","  batchSize = 10\n","\n","  for epoch in range(nEpochs):\n","    totalLoss = 0.0\n","\n","    (sentences_shuffled, tags_shuffled) = shuffle_sentences(sentences, tags)\n","    for batch in tqdm.notebook.tqdm(range(0, len(sentences), batchSize), leave=False):\n","\n","      lstm.zero_grad()\n","      #TODO: Impelement gradient update.\n","      # inference\n","      batch_examples = sentences_shuffled[batch:min(len(sentences)-1, batch+batchSize)]\n","      batch_targets = tags_shuffled[batch:min(len(sentences)-1, batch+batchSize)]\n","\n","      batch_examples_idx = prepare_input(sentences2indices(batch_examples, word2i))[0].cuda()\n","      batch_targets_idx = prepare_input(sentences2indices(batch_targets, tag2i))[0].cuda()\n","      batch_targets_onehot = prepare_output_onehot(batch_targets_idx).cuda()\n","\n","      predictions = lstm.forward(batch_examples_idx).cuda()\n","\n","      # compute loss\n","      loss = torch.sum(torch.einsum('bij,bij->bi', -predictions, batch_targets_onehot))\n","\n","      totalLoss += loss\n","      # backprop and optimize\n","      loss.backward()\n","      optimizer.step()\n","\n","    print(f\"loss on epoch {epoch} = {totalLoss}\")\n","    lstm.write_predictions(sentences_dev, 'dev_pred')   #Performance on dev set\n","    print('conlleval:')\n","    print(subprocess.Popen('paste dev dev_pred | perl conlleval.pl -d \"\\t\"', shell=True, stdout=subprocess.PIPE,stderr=subprocess.STDOUT).communicate()[0].decode('UTF-8'))\n","\n","    if epoch % 10 == 0:\n","      s = sample(range(len(sentences_dev)), 5)\n","      lstm.print_predictions([sentences_dev[i] for i in s], [tags_dev[i] for i in s])\n","\n","lstm = BasicLSTMtagger(DIM_HID=500, DIM_EMB=300).cuda()\n","train_basic_lstm(sentences_train, tags_train, lstm)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["29146\n","32\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:63: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2fd08084e2014bfe8f48d26fc6c4fd71","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=1499.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\rloss on epoch 0 = 53864.3359375\n","conlleval:\n","processed 51578 tokens with 5942 phrases; found: 5624 phrases; correct: 4203.\n","accuracy:  95.17%; precision:  74.73%; recall:  70.73%; FB1:  72.68\n","                 : precision:   0.00%; recall:   0.00%; FB1:   0.00  1\n","              LOC: precision:  81.56%; recall:  78.99%; FB1:  80.25  1779\n","             MISC: precision:  65.25%; recall:  58.24%; FB1:  61.55  823\n","              ORG: precision:  61.80%; recall:  54.29%; FB1:  57.80  1178\n","              PER: precision:  80.68%; recall:  80.73%; FB1:  80.71  1843\n","\n","----------------------------\n","-START-/START/START The/O/O titles/O/O of/O/O his/O/O other/O/O novels/O/O translate/O/O as/O/O \"/O/O In/O/I-MISC the/O/I-MISC Year/I-MISC/I-MISC of/O/I-MISC January/O/I-MISC \"/O/O (/O/O 1963/O/O )/O/O ,/O/O \"/O/O The/O/I-MISC Collapse/O/I-MISC \"/O/O (/O/O 1964/O/O )/O/O ,/O/O \"/O/O Sleeping/O/I-MISC Bread/I-MISC/I-MISC \"/O/O (/O/O 1975/O/O )/O/O ,/O/O \"/O/O The/O/I-MISC Decaying/O/I-MISC Mansion/O/I-MISC \"/O/O (/O/O 1977/O/O )/O/O and/O/O \"/O/O A/O/I-MISC World/I-MISC/I-MISC of/O/I-MISC Things/O/I-MISC \"/O/O (/O/O 1982/O/O )/O/O ,/O/O followed/O/O by/O/O \"/O/O The/O/I-MISC Knot/O/I-MISC ,/O/O \"/O/O \"/O/O Soul/O/I-MISC Alone/O/I-MISC \"/O/O and/O/O ,/O/O most/O/O recently/O/O ,/O/O \"/O/O A/O/I-MISC Woman/O/I-MISC ./O/O \"/O/O -END-/END/END\n","Predicted:\t ['START', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'END']\n","Gold:\t\t ['START', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'END']\n","----------------------------\n","-START-/START/START Extras/O/O (/O/O lb-3/O/O nb-6/O/O w-7/O/O )/O/O 16/O/O -END-/END/END\n","Predicted:\t ['START', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'END']\n","Gold:\t\t ['START', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'END']\n","----------------------------\n","-START-/START/START He/O/O said/O/O he/O/O would/O/O \"/O/O serve/O/O until/O/O the/O/O end/O/O \"/O/O as/O/O cardinal/O/O ./O/O -END-/END/END\n","Predicted:\t ['START', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'END']\n","Gold:\t\t ['START', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'END']\n","----------------------------\n","-START-/START/START 11./O/O Stephen/I-PER/I-PER Ames/I-PER/I-PER (/O/O Trinidad/I-LOC/I-LOC )/O/O 211,175/O/O -END-/END/END\n","Predicted:\t ['START', 'O', 'I-PER', 'I-PER', 'O', 'I-LOC', 'O', 'O', 'END']\n","Gold:\t\t ['START', 'O', 'I-PER', 'I-PER', 'O', 'I-LOC', 'O', 'O', 'END']\n","----------------------------\n","-START-/START/START Controversial/O/O Australian/I-MISC/I-MISC Anthony/I-PER/I-PER Hill/I-PER/I-PER called/O/O Jansher/I-PER/I-PER Khan/O/I-PER a/O/O cheat/O/O during/O/O his/O/O acrimonious/O/O defeat/O/O by/O/O the/O/O world/O/O number/O/O one/O/O in/O/O the/O/O Hong/I-LOC/I-MISC Kong/I-MISC/I-MISC Open/I-MISC/I-MISC semifinals/O/O on/O/O Saturday/O/O ./O/O -END-/END/END\n","Predicted:\t ['START', 'O', 'I-MISC', 'I-PER', 'I-PER', 'O', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-LOC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'END']\n","Gold:\t\t ['START', 'O', 'I-MISC', 'I-PER', 'I-PER', 'O', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'END']\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"192b8a20fc69404ab4f99f2830b384d9","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=1499.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\rloss on epoch 1 = 26884.64453125\n","conlleval:\n","processed 51578 tokens with 5942 phrases; found: 5828 phrases; correct: 4653.\n","accuracy:  96.36%; precision:  79.84%; recall:  78.31%; FB1:  79.07\n","              LOC: precision:  84.45%; recall:  86.61%; FB1:  85.51  1884\n","             MISC: precision:  75.75%; recall:  60.30%; FB1:  67.15  734\n","              ORG: precision:  69.42%; recall:  64.65%; FB1:  66.95  1249\n","              PER: precision:  83.58%; recall:  88.98%; FB1:  86.20  1961\n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e72756bee8c0441fb24c1b44297c068d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=1499.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\rloss on epoch 2 = 20848.80859375\n","conlleval:\n","processed 51578 tokens with 5942 phrases; found: 5881 phrases; correct: 4868.\n","accuracy:  96.89%; precision:  82.78%; recall:  81.93%; FB1:  82.35\n","              LOC: precision:  85.92%; recall:  91.02%; FB1:  88.40  1946\n","             MISC: precision:  77.61%; recall:  65.40%; FB1:  70.98  777\n","              ORG: precision:  73.41%; recall:  71.44%; FB1:  72.41  1305\n","              PER: precision:  88.24%; recall:  88.76%; FB1:  88.50  1853\n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5c21c8bd50c24a33ae8171eec6d1badc","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=1499.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-bbdc3cd280a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0mlstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBasicLSTMtagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDIM_HID\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDIM_EMB\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mtrain_basic_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-11-bbdc3cd280a0>\u001b[0m in \u001b[0;36mtrain_basic_lstm\u001b[0;34m(sentences, tags, lstm)\u001b[0m\n\u001b[1;32m     49\u001b[0m       \u001b[0;31m# backprop and optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"loss on epoch {epoch} = {totalLoss}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adadelta.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     86\u001b[0m                        \u001b[0mrho\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                        \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                        weight_decay)\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madadelta\u001b[0;34m(params, grads, square_avgs, acc_deltas, lr, rho, eps, weight_decay)\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0msquare_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msquare_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macc_delta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"Om69KEe_KKxs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616004228361,"user_tz":240,"elapsed":5524,"user":{"displayName":"Collin Avidano","photoUrl":"","userId":"00144222138809176447"}},"outputId":"485962ee-be77-403d-efdd-3d16713dc30c"},"source":["#Evaluation on test data\n","lstm.write_predictions(sentences_test, 'test_pred_lstm.txt')\n","!wget https://raw.githubusercontent.com/aritter/twitter_nlp/master/data/annotated/wnut16/conlleval.pl\n","!paste test test_pred_lstm.txt | perl conlleval.pl -d \"\\t\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2021-03-17 18:03:47--  https://raw.githubusercontent.com/aritter/twitter_nlp/master/data/annotated/wnut16/conlleval.pl\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 12754 (12K) [text/plain]\n","Saving to: ‘conlleval.pl.1’\n","\n","conlleval.pl.1      100%[===================>]  12.46K  --.-KB/s    in 0s      \n","\n","2021-03-17 18:03:47 (82.5 MB/s) - ‘conlleval.pl.1’ saved [12754/12754]\n","\n","processed 46666 tokens with 5648 phrases; found: 5612 phrases; correct: 4427.\n","accuracy:  96.09%; precision:  78.88%; recall:  78.38%; FB1:  78.63\n","              LOC: precision:  81.53%; recall:  85.49%; FB1:  83.47  1749\n","             MISC: precision:  67.77%; recall:  64.10%; FB1:  65.89  664\n","              ORG: precision:  71.67%; recall:  70.98%; FB1:  71.32  1645\n","              PER: precision:  88.29%; recall:  84.85%; FB1:  86.53  1554\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PvyY4qzvuBzK"},"source":["## Initialization with GloVe Embeddings (5 points)\n","\n","If you haven't already, implement the `init_glove()` method in `BasicLSTMtagger` above.\n","\n","Rather than initializing word embeddings randomly, it is common to use learned word embeddings (GloVe or Word2Vec), as discussed in lecture.  To make this simpler, we have already pre-filtered [GloVe](https://nlp.stanford.edu/projects/glove/) embeddings to only contain words in the vocabulary of the CoNLL NER dataset, and loaded them into a dictionary (`GloVe`) at the beginning of this notebook.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"TdJSNuMKuN8J"},"source":["## Character Embeddings (10 points)\n","\n","Now that you have your basic LSTM tagger working, the next step is to add a convolutional network that computes word embeddings from character representations of words.  See Figure 2 and Figure 3 in the [Ma and Hovy](https://www.aclweb.org/anthology/P16-1101.pdf) paper.  We have provided code in `sentences2input_tensors` to convert sentences into lists of word and character indices.  See also [nn.Conv1d](https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html) and [MaxPool1d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool1d.html).\n","\n","Make sure to save your predictions on the test set, for submission to GradeScope.  You should be able to achieve 90 F1 / 85 F1 on the dev/test sets."]},{"cell_type":"code","metadata":{"id":"NwiKOvSs7Xgx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616004334954,"user_tz":240,"elapsed":1273,"user":{"displayName":"Collin Avidano","photoUrl":"","userId":"00144222138809176447"}},"outputId":"f57470e3-852c-41bb-81ed-21db9b9b6845"},"source":["#For F.max_pool1d()\n","import torch.nn.functional as F\n","\n","#class CharLSTMtagger(nn.Module):\n","class CharLSTMtagger(BasicLSTMtagger):\n","    def __init__(self, DIM_EMB=10, DIM_CHAR_EMB=30, DIM_HID=10):\n","        super(CharLSTMtagger, self).__init__(DIM_EMB=DIM_EMB, DIM_HID=DIM_HID)\n","        NUM_TAGS = max(tag2i.values())+1\n","\n","        (self.DIM_EMB, self.NUM_TAGS) = (DIM_EMB, NUM_TAGS)\n","        #TODO: Initialize parameters.\n","        self.init_glove(GloVe)\n","        self.char_embed = nn.Embedding(len(char2i) + 2, DIM_CHAR_EMB)\n","        self.dropout = nn.Dropout(p=0.5)\n","\n","        # Check this for padding later\n","        self.conv = nn.Conv1d(DIM_CHAR_EMB, DIM_CHAR_EMB, 3)\n","\n","        # self.lstm = nn.LSTM(DIM_EMB + DIM_CHAR_EMB, DIM_HID, batch_first=True, dropout=0.5, bidirectional=True)\n","        self.lstm = nn.LSTM(DIM_EMB + DIM_CHAR_EMB, DIM_HID, batch_first=True, bidirectional=True)\n","        self.fc = nn.Linear(DIM_HID*2, NUM_TAGS)\n","        self.softmax = nn.LogSoftmax(dim=2)\n","\n","    def forward(self, X, X_char, train=False):\n","        #TODO: Implement the forward computation.\n","        # Get char embeddings\n","        char_embeddings = self.char_embed(X_char)\n","\n","        # Dropout on Char embeddings\n","        x = self.dropout(char_embeddings)\n","\n","        # CNN to get char representation\n","        x = x.permute(0, 1, 3, 2)\n","        x = torch.reshape(x,(x.shape[0] * x.shape[1], x.shape[2], x.shape[3]))\n","        x = self.conv(x)\n","        char_rep = F.max_pool1d(x, x.shape[2])\n","        char_rep = torch.reshape(char_rep,(char_embeddings.shape[0], \n","                                           char_embeddings.shape[1],\n","                                           char_embeddings.shape[3]))\n","\n","        # get word embeddings\n","        word_embeddings = self.embed(X)\n","\n","        # Concat char representation with word embedding\n","        merged_representation = torch.cat((char_rep, word_embeddings), dim=2)\n","\n","        # Droput on LSTM Input\n","        # x = self.dropout(merged_representation)\n","        # LSTM\n","        out, hidden = self.lstm(merged_representation)\n","        # # Dropout on LSTM Output\n","        # out = self.dropout(out)\n","        \n","\n","        # Score to tag prob space\n","        tag_scores = self.fc(out)\n","        tag_probs = self.softmax(tag_scores)\n","        return tag_probs\n","\n","    def sentences2input_tensors(self, sentences):\n","      (X, X_mask)   = prepare_input(sentences2indices(sentences, word2i))\n","      X_char        = prepare_input_char(sentences2indicesChar(sentences, char2i))\n","      return (X, X_mask, X_char)\n","\n","    def inference(self, sentences):\n","      (X, X_mask, X_char) = self.sentences2input_tensors(sentences)\n","      pred = self.forward(X.cuda(), X_char.cuda()).argmax(dim=2)\n","      return [[i2tag[pred[i,j].item()] for j in range(len(sentences[i]))] for i in range(len(sentences))]\n","\n","    def print_predictions(self, words, tags):\n","      Y_pred = self.inference(words)\n","      for i in range(len(words)):\n","        print(\"----------------------------\")\n","        print(\" \".join([f\"{words[i][j]}/{Y_pred[i][j]}/{tags[i][j]}\" for j in range(len(words[i]))]))\n","        print(\"Predicted:\\t\", Y_pred[i])\n","        print(\"Gold:\\t\\t\", tags[i])\n","\n","lstm        = CharLSTMtagger(DIM_HID=7, DIM_EMB=300)\n","lstm_output = lstm.forward(prepare_input(X[0:5])[0], prepare_input_char(X_char[0:5]))\n","Y_onehot    = prepare_output_onehot(Y[0:5])\n","\n","print(\"lstm output shape:\", lstm_output.shape)\n","print(\"Y onehot shape:\", Y_onehot.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["29146\n","32\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:63: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"],"name":"stderr"},{"output_type":"stream","text":["lstm output shape: torch.Size([5, 32, 10])\n","Y onehot shape: torch.Size([5, 32, 10])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2FmQqNC_CB7Z","colab":{"base_uri":"https://localhost:8080/","height":487,"referenced_widgets":["d68e63144cf745f6a4d88c761ccfa0d7","064cfc3ee5924fb6b0c03ce565d1c5eb","5ee64e4e1fe64667912fd82ade65cce8","599dc48752784337b635aadc0679c9dd","1bab511fba9e4f26a486aef195fec324","82cb79d9af514a9d8581aa7407444bcf","19d570e282da482ab05391648bbbe672","f2b727b7759c4a10b61522d204e259b1"]},"executionInfo":{"status":"error","timestamp":1616004342261,"user_tz":240,"elapsed":4029,"user":{"displayName":"Collin Avidano","photoUrl":"","userId":"00144222138809176447"}},"outputId":"e72a54d6-b414-4b24-e559-45ff05c8f1f7"},"source":["#Training LSTM w/ character embeddings.\n","\n","nEpochs = 10\n","\n","def train_char_lstm(sentences, tags, lstm):\n","  optimizer = optim.Adadelta(lstm.parameters(), lr=0.1)\n","  #TODO: initialize optimizer\n","\n","  batchSize = 10\n","\n","  for epoch in range(nEpochs):\n","    totalLoss = 0.0\n","\n","    (sentences_shuffled, tags_shuffled) = shuffle_sentences(sentences, tags)\n","    for batch in tqdm.notebook.tqdm(range(0, len(sentences), batchSize), leave=False):\n","      lstm.zero_grad()\n","      #TODO: Gradient update\n","\n","      batch_examples = sentences_shuffled[batch:min(len(sentences)-1, batch+batchSize)]\n","      batch_targets = tags_shuffled[batch:min(len(sentences)-1, batch+batchSize)]\n","\n","      X, X_mask, X_char = char_lstm.sentences2input_tensors(batch_examples)\n","      batch_targets_idx = prepare_input(sentences2indices(batch_targets, tag2i))[0].cuda()\n","      batch_targets_onehot = prepare_output_onehot(batch_targets_idx).cuda()\n","\n","      predictions = char_lstm.forward(X.cuda(), X_char.cuda()).cuda()\n","\n","      loss = torch.sum(torch.einsum('bij,bij->bi', -predictions, batch_targets_onehot))\n","    \n","      totalLoss += loss\n","      loss.backward()\n","      optimizer.step()\n","\n","\n","    print(f\"loss on epoch {epoch} = {totalLoss}\")\n","    lstm.write_predictions(sentences_dev, 'dev_pred')   #Performance on dev set\n","    print('conlleval:')\n","    print(subprocess.Popen('paste dev dev_pred | perl conlleval.pl -d \"\\t\"', shell=True, stdout=subprocess.PIPE,stderr=subprocess.STDOUT).communicate()[0].decode('UTF-8'))\n","\n","    if epoch % 10 == 0:\n","      s = sample(range(len(sentences_dev)), 5)\n","      lstm.print_predictions([sentences_dev[i] for i in s], [tags_dev[i] for i in s])\n","\n","char_lstm = CharLSTMtagger(DIM_HID=500, DIM_EMB=300).cuda()\n","train_char_lstm(sentences_train, tags_train, char_lstm)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["29146\n","32\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:63: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d68e63144cf745f6a4d88c761ccfa0d7","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=1499.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-c9585af65309>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mchar_lstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCharLSTMtagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDIM_HID\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDIM_EMB\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mtrain_char_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_lstm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-14-c9585af65309>\u001b[0m in \u001b[0;36mtrain_char_lstm\u001b[0;34m(sentences, tags, lstm)\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchar_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences2input_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_examples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0mbatch_targets_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences2indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag2i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m       \u001b[0mbatch_targets_onehot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_output_onehot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_targets_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchar_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_char\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-ada52c777d07>\u001b[0m in \u001b[0;36mprepare_output_onehot\u001b[0;34m(Y_list, NUM_TAGS)\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m    \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mY_onehot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m   \u001b[0mY_padded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_onehot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mY_padded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"i9NaMeuCnS3r","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616004351334,"user_tz":240,"elapsed":6592,"user":{"displayName":"Collin Avidano","photoUrl":"","userId":"00144222138809176447"}},"outputId":"013a59fd-86ed-4ac1-8bd1-88a47c53c250"},"source":["#Evaluation on test set\n","char_lstm.write_predictions(sentences_test, 'test_pred_cnn_lstm.txt')\n","!wget https://raw.githubusercontent.com/aritter/twitter_nlp/master/data/annotated/wnut16/conlleval.pl\n","!paste test test_pred_cnn_lstm.txt | perl conlleval.pl -d \"\\t\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2021-03-17 18:05:50--  https://raw.githubusercontent.com/aritter/twitter_nlp/master/data/annotated/wnut16/conlleval.pl\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 12754 (12K) [text/plain]\n","Saving to: ‘conlleval.pl.2’\n","\n","\rconlleval.pl.2        0%[                    ]       0  --.-KB/s               \rconlleval.pl.2      100%[===================>]  12.46K  --.-KB/s    in 0.001s  \n","\n","2021-03-17 18:05:50 (17.7 MB/s) - ‘conlleval.pl.2’ saved [12754/12754]\n","\n","processed 46666 tokens with 5648 phrases; found: 1818 phrases; correct: 726.\n","accuracy:  84.73%; precision:  39.93%; recall:  12.85%; FB1:  19.45\n","                 : precision:   0.00%; recall:   0.00%; FB1:   0.00  1\n","              LOC: precision:  88.35%; recall:   5.46%; FB1:  10.28  103\n","             MISC: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n","              ORG: precision:  52.70%; recall:   4.70%; FB1:   8.62  148\n","              PER: precision:  35.57%; recall:  34.45%; FB1:  35.00  1566\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5C4P4Ycm1CT2"},"source":["## Conditional Random Fields (15 points)\n","\n","Now we are ready to add a CRF layer to the `CharacterLSTMTagger`.  To train the model, implement `conditional_log_likelihood`, using the score (unnormalized log probability) of the gold sequence, in addition to the partition function, $Z(X)$, which is computed using the forward algorithm.  Then, you can simply use Pytorch's automatic differentiation to compute gradients by running backpropagation through the computation graph of the dynamic program (this should be very simple, so long as you are able to correctly implement the forward algorithm using a computation graph that is supported by PyTorch).  This approach to computing gradients for CRFs is discussed in Section 7.5.3 of the [Eisenstein Book](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf)\n","\n","You will also need to implement the Viterbi algorithm for inference during decoding.\n","\n","After including CRF training and Viterbi decoding, you should be getting about 92 F1 / 88 F1 on the dev and test set, respectively.\n","\n","**IMPORTANT:** Note that training will be substantially slower this time - depending on the efficiency of your implementation, it could take about 5 minutes per epoch (e.g. 50 minutes for 10 iterations).  It is recommended to start out training on a single batch of data (and testing on this same batch), so that you can quickly debug, making sure your model can memorize the labels on a single batch, and then optimize your code.  Once you are fairly confident your code is working properly, then you can train using the full dataset.  We have provided a (commented out) line of code to switch between training on a single batch and the full dataset below.\n","\n","**Hint #1:** While debugging your implementation of the Forward algorithm it is helpful to look at the loss during training.  The loss should never be less than zero (the log-likelihood should always be negative).\n","\n","**Hint #2:** To sum log-probabilities in a numerically stable way at the end of the Forward algorithm, you will want to use [`torch.logsumexp`](https://pytorch.org/docs/stable/generated/torch.logsumexp.html)."]},{"cell_type":"code","metadata":{"id":"IKBomV-L6SmZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616004358879,"user_tz":240,"elapsed":1923,"user":{"displayName":"Collin Avidano","photoUrl":"","userId":"00144222138809176447"}},"outputId":"26ff18f6-a7ee-497b-8929-6537ea77fa71"},"source":["#For F.max_pool1d()\n","import torch.nn.functional as F\n","\n","class LSTM_CRFtagger(CharLSTMtagger):\n","    def __init__(self, DIM_EMB=10, DIM_CHAR_EMB=30, DIM_HID=10, N_TAGS=max(tag2i.values())+1):\n","      super(LSTM_CRFtagger, self).__init__(DIM_EMB=DIM_EMB, DIM_HID=DIM_HID, DIM_CHAR_EMB=DIM_CHAR_EMB)\n","\n","      #TODO: Initialize parameters.\n","      NUM_TAGS = max(tag2i.values())+1\n","\n","      (self.DIM_EMB, self.NUM_TAGS) = (DIM_EMB, NUM_TAGS)\n","      #TODO: Initialize parameters.\n","      self.init_glove(GloVe)\n","      self.char_embed = nn.Embedding(len(char2i) + 2, DIM_CHAR_EMB)\n","      self.dropout = nn.Dropout(p=0.5)\n","\n","      # Check this for padding later\n","      self.conv = nn.Conv1d(DIM_CHAR_EMB, DIM_CHAR_EMB, 3)\n","      self.pool = nn.MaxPool1d(DIM_CHAR_EMB, 1)\n","\n","      self.lstm = nn.LSTM(DIM_EMB + DIM_CHAR_EMB, DIM_HID, batch_first=True,\n","                          bidirectional=True)\n","      # self.lstm = nn.LSTM(DIM_EMB + DIM_CHAR_EMB, DIM_HID, batch_first=True,\n","      # dropout=0.5, bidirectional=True)\n","\n","      self.fc = nn.Linear(DIM_HID*2, NUM_TAGS)\n","\n","      self.transitionWeights = nn.Parameter(torch.zeros((N_TAGS, N_TAGS), requires_grad=True))\n","      nn.init.normal_(self.transitionWeights)\n","\n","      self.START_IND = tag2i.get('START')\n","      self.END_IND = tag2i.get('END')\n","\n","      self.transitionWeights.data[self.START_IND, :] = -10000.0\n","      self.transitionWeights.data[:, self.END_IND] = -10000.0\n","\n","\n","    def forward(self, X, X_char, train=False):\n","      #TODO: Implement the forward computation.\n","      # Get char embeddings\n","      char_embeddings = self.char_embed(X_char)\n","\n","      # Dropout on Char embeddings\n","      x = self.dropout(char_embeddings)\n","\n","      # CNN to get char representation\n","      x = x.permute(0, 1, 3, 2)\n","      x = torch.reshape(x,(x.shape[0] * x.shape[1], x.shape[2], x.shape[3]))\n","      x = self.conv(x)\n","      char_rep = self.pool(x)\n","      char_rep = torch.reshape(char_rep,(char_embeddings.shape[0], \n","                                          char_embeddings.shape[1],\n","                                          char_embeddings.shape[3]))\n","\n","      # get word embeddings\n","      word_embeddings = self.embed(X)\n","\n","      # Concat char representation with word embedding\n","      merged_representation = torch.cat((char_rep, word_embeddings), dim=2)\n","\n","      # Droput on LSTM Input\n","      x = self.dropout(merged_representation)\n","      # LSTM\n","      out, hidden = self.lstm(x)\n","      # Dropout on LSTM Output\n","      out = self.dropout(out)\n","\n","      #After you take the dot product between the LSTM features and a \n","      #weight vector for a particular label, this will give you the emission \n","      #score for that input/label.\n","      tag_scores = self.fc(out)\n","\n","      # Output should be of shape batchsize, max sentence length in words, Num tags(onehot vector)\n","      return tag_scores\n","      # these scores are then used below as input to the viterbi algo\n","\n","\n","### INFERENCE START\n","\n","    # finds highest prob tag sequence for given input sentence\n","    # For inference only\n","    def viterbi(self, lstm_scores, sLen):\n","      #TODO: Implement Viterbi algorithm, soring backpointers to recover the argmax sequence.  Returns the argmax sequence in addition to its unnormalized conditional log-likelihood.\n","      \n","      backpointers = []\n","      # current_vs = lstm_scores[0].view(1, -1).cuda()\n","      \n","      # TESTING LINE\n","      # current_vs = torch.full((1, self.NUM_TAGS), -10000.0)\n","      current_vs = torch.zeros((1, self.NUM_TAGS)).cuda()\n","      current_vs[0,self.START_IND] = lstm_scores[0,self.START_IND]\n","      current_vs += self.transitionWeights[:, self.START_IND]\n","\n","      # print(\"self.START_IND \", self.START_IND)\n","      # print(\"self.END_IND \", self.END_IND)\n","      # print(\"self.NUM_TAGS\", self.NUM_TAGS)\n","\n","      for word_ind in range(1, sLen - 1):\n","        backpointers_t = []  # holds the backpointers for this step\n","        next_vs = torch.zeros(self.NUM_TAGS).cuda()  # holds the viterbi variables for this step\n","\n","        # Zeroing out start and end scores\n","        current_vs[0,self.START_IND] = 0.0\n","        current_vs[0,self.END_IND] = 0.0\n","\n","\n","        for next_tag in range(self.NUM_TAGS):\n","          # find v_t+1 + phi_trans(s_t+1|s_t) and assign backpointers\n","          tag_next_vs = current_vs.cuda() + self.transitionWeights[next_tag]\n","          # print(\"tag_next_vs.shape\",next_tag_var.shape)\n","          best_tag_id = torch.argmax((tag_next_vs),1)\n","          # print(\"best_tag_id\" ,best_tag_id)\n","          backpointers_t.append(best_tag_id)\n","          next_vs[next_tag] = tag_next_vs[0][best_tag_id].view(1)\n","\n","        # phi_emission(x_t+1|s_t+1)\n","        word_scores = lstm_scores[word_ind]\n","        # Zeroing out start and end emission probs\n","        word_scores[self.START_IND] = 0.0\n","        word_scores[self.END_IND] = 0.0\n","        # v_t+1 = phi_trans(s_t+1 | s_t) + phi_emission(x_t+1|s_t+1)\n","        current_vs = (next_vs + word_scores).view(1, -1)\n","        backpointers.append(backpointers_t)\n","\n","      current_vs += self.transitionWeights[self.END_IND]\n","      best_tag_id = torch.argmax((current_vs),1)\n","\n","      # print(\"best_tag_id \", best_tag_id)\n","      # print(\"self.END_IND \", self.END_IND)\n","      path_score = current_vs[0][best_tag_id]\n","\n","      # Follow the back pointers to decode the best path.\n","      best_path = [int(self.END_IND), int(best_tag_id)]\n","      for backpointers_t in reversed(backpointers):\n","        best_tag_id = backpointers_t[best_tag_id]\n","        best_path.append(int(best_tag_id))\n","\n","      best_path.append(int(self.START_IND))\n","      best_path.reverse()\n","      \n","      # print(i2tag)\n","      # print(\"best_path\", best_path)\n","      # for item in best_path:\n","      #   print(item, \" is tag \",i2tag[item])\n","      \n","      return torch.tensor(best_path), path_score\n","\n","\n","    #Computes Viterbi sequences on a batch of data.\n","    def viterbi_batch(self, sentences):\n","      viterbiSeqs = []\n","      (X, X_mask, X_char) = self.sentences2input_tensors(sentences)\n","      lstm_scores = self.forward(X.cuda(), X_char.cuda())\n","      # print(\"len(sentences)\",len(sentences))\n","      for s in range(len(sentences)):\n","        # print(\"sentence\", sentences[s])\n","        (viterbiSeq, ll) = self.viterbi(lstm_scores[s].cuda(), len(sentences[s]))\n","        viterbiSeqs.append(viterbiSeq)\n","      # print(\"viterbiSeqs\",viterbiSeqs)\n","      return viterbiSeqs\n","\n","### INFERENCE END\n","\n","### TRAINING START\n","\n","    #Forward algorithm for a single sentence\n","    #Efficiency will eventually be important here.  We recommend you start by \n","    #training on a single batch and make sure your code can memorize the \n","    #training data.  Then you can go back and re-write the inner loop using \n","    #tensor operations to speed things up.\n","\n","    # computes paritition function P(Z) or the denominator of the CRF\n","    def forward_algorithm(self, lstm_scores, sLen):\n","      #TODO: implement forward algorithm.\n","      current_alphas = torch.zeros((1, self.NUM_TAGS)).cuda()\n","      current_alphas[0,self.START_IND] = lstm_scores[0,self.START_IND]\n","      current_alphas += self.transitionWeights[:, self.START_IND]\n","\n","      # Iterate through the sentence\n","      for word_ind in range(1, sLen - 1):\n","        next_alphas = torch.zeros(self.NUM_TAGS).cuda()\n","        word_score = lstm_scores[word_ind]\n","\n","        # Zeroing out start and end scores  \n","        current_alphas[0,self.START_IND] = 0.0\n","        current_alphas[0,self.END_IND] = 0.0\n","        \n","        # Zeroing out start and end emission probs\n","        word_score[self.START_IND] = 0.0\n","        word_score[self.END_IND] = 0.0\n","\n","        for next_tag in range(self.NUM_TAGS):\n","          # computing a_t+1 = sum a_t(s_t) + phi_trans(s_t+1 | s_t) + phi_emission(x_t+1|s_t+1)\n","          emission_potential = word_score[next_tag].view(1, -1).expand(1, self.NUM_TAGS).cuda()\n","          transmission_potential = self.transitionWeights[next_tag].view(1, -1).cuda()\n","          tag_next_alpha = (current_alphas + transmission_potential + emission_potential).cuda()\n","          next_alphas[next_tag] = torch.logsumexp(tag_next_alpha,dim=1).view(1).cuda()\n","\n","        current_alphas = next_alphas.view(1, -1)\n","      current_alphas += self.transitionWeights[self.END_IND] \n","      return torch.logsumexp(current_alphas,dim=1)\n","      # returning log of partition function\n","\n","    def gold_score(self, lstm_scores, Y):\n","      #TODO: compute score of gold sequence Y (unnormalized conditional log-probability)\n","      score = torch.clone(lstm_scores[0,Y[0]]).cuda()\n","      \n","      for i in range(Y.shape[0] - 1):\n","          if (Y[i] == self.END_IND):\n","            break\n","          word_score = lstm_scores[i].cuda()\n","          score = score + self.transitionWeights[Y[i + 1], Y[i]] + word_score[Y[i + 1]]\n","      return score\n","\n","\n","    def conditional_log_likelihood(self, sentences, tags, train=True):\n","      #Todo: compute conditional log likelihood of Y (use forward_algorithm and gold_score)\n","\n","      (X, X_mask, X_char) = self.sentences2input_tensors(sentences)\n","      lstm_scores = self.forward(X.cuda(), X_char.cuda()).cuda()\n","\n","      tags_idx = prepare_input(sentences2indices(tags, tag2i))[0].cuda()\n","\n","      cond_log_likelihoods = torch.zeros([len(sentences)]) # size of batch so num of sentences per batch\n","\n","      for s in range(len(sentences)):\n","        # print(\"sentence \", s)\n","        # print(\"sentences[s] \", sentences[s])\n","        forward_score = self.forward_algorithm(lstm_scores[s], len(sentences[s])).cuda() # May need to use something other than len here\n","        gold_score = self.gold_score(lstm_scores[s].cuda(), tags_idx[s].cuda())\n","\n","        # print(\"forward_score: \", forward_score)\n","        # print(\"gold_score: \", gold_score)\n","\n","        # THIS IS WHAT WAS ON PIAZZA\n","        cond_log_likelihoods[s] = forward_score - gold_score\n","        # print(\"cond_log_likelihoods[s]: \", s, cond_log_likelihoods[s])\n","      \n","      loss = torch.sum(cond_log_likelihoods)\n","      # print(\"cond_log_likelihood batch\", loss, \"\\n\\n\")\n","      return loss\n","\n","\n","### TRAINING END\n","\n","\n","    def print_predictions(self, words, tags):\n","      Y_pred = self.inference(words)\n","      for i in range(len(words)):\n","        print(\"----------------------------\")\n","        print(\" \".join([f\"{words[i][j]}/{Y_pred[i][j]}/{tags[i][j]}\" for j in range(len(words[i]))]))\n","        print(\"Predicted:\\t\", [Y_pred[i][j] for j in range(len(words[i]))])\n","        print(\"Gold:\\t\\t\", tags[i])\n","\n","    #Need to use Viterbi this time.\n","    # REVERT THIS LATER\n","    def inference(self, sentences, viterbi=True):\n","      pred = self.viterbi_batch(sentences)\n","      return [[i2tag[pred[i][j].item()] for j in range(len(sentences[i]))] for i in range(len(sentences))]\n","  \n","lstm_crf = LSTM_CRFtagger(DIM_EMB=300).cuda()   "],"execution_count":null,"outputs":[{"output_type":"stream","text":["29146\n","32\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:63: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"CjcSzfi27uOM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615990638955,"user_tz":240,"elapsed":346,"user":{"displayName":"Collin Avidano","photoUrl":"","userId":"00144222138809176447"}},"outputId":"c128b5e3-2d10-4aa1-bba3-242a9177d5ea"},"source":["print(lstm_crf.conditional_log_likelihood(sentences_dev[0:3], tags_dev[0:3]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor(33.9177, grad_fn=<SumBackward0>)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"in7f4nDWc6dd","colab":{"base_uri":"https://localhost:8080/","height":142,"referenced_widgets":["d170908978cf4c96aac39f19644f2971","592a68199d754ee49d500ea7a87b53e3","02bbabf4502948a0b783f63761488517","aa98f8019b794bce9a2bbf5345126d65","75602845b9b6478c8c996e7d3a63f167","72252639fbbf42728128f715367fd447","b7f39b1853f4477ba73fd8a2e8ee24d1","ba7810efaa5348f0b7a4c03cb8cf0e9c"]},"outputId":"e6961230-c1fb-4dd5-ad8e-846ed83f6591"},"source":["#CharLSTM-CRF Training\n","import tqdm\n","import os\n","import subprocess\n","import random\n","\n","nEpochs=10\n","\n","#Get CoNLL evaluation script\n","os.system('wget https://raw.githubusercontent.com/aritter/twitter_nlp/master/data/annotated/wnut16/conlleval.pl')\n","\n","def train_crf_lstm(sentences, tags, lstm):\n","  optimizer = optim.Adadelta(lstm.parameters(), lr=1.0)\n","  #TODO: initialize optimizer\n","\n","  batchSize = 10\n","\n","  for epoch in range(nEpochs):\n","    totalLoss = 0.0\n","    lstm.train()\n","\n","    #Shuffle the sentences\n","    (sentences_shuffled, tags_shuffled) = shuffle_sentences(sentences, tags)\n","    for batch in tqdm.notebook.tqdm(range(0, len(sentences), batchSize), leave=False):\n","      lstm.zero_grad()\n","      #TODO: take gradient step on a batch of data.\n","\n","      batch_examples = sentences_shuffled[batch:min(len(sentences)-1, batch+batchSize)]\n","      batch_targets = tags_shuffled[batch:min(len(sentences)-1, batch+batchSize)]\n","\n","      loss = lstm.conditional_log_likelihood(batch_examples, batch_targets)\n","      # print(\"loss\", loss)\n","    \n","      totalLoss += loss\n","      loss.backward()\n","      optimizer.step()\n","\n","\n","    print(f\"loss on epoch {epoch} = {totalLoss}\")\n","    lstm.write_predictions(sentences_dev, 'dev_pred')   #Performance on dev set\n","    print('conlleval:')\n","    print(subprocess.Popen('paste dev dev_pred | perl conlleval.pl -d \"\\t\"', shell=True, stdout=subprocess.PIPE,stderr=subprocess.STDOUT).communicate()[0].decode('UTF-8'))\n","\n","    if epoch % 10 == 0:\n","      lstm.eval()\n","      s = random.sample(range(50), 5)\n","      lstm.print_predictions([sentences_train[i] for i in s], [tags_train[i] for i in s])   #Print predictions on train data (useful for debugging)\n","\n","crf_lstm = LSTM_CRFtagger(DIM_HID=500, DIM_EMB=300, DIM_CHAR_EMB=30).cuda()\n","\n","#REMEMBER TO CHANGE THIS BACK\n","\n","# I just cant any more I literally lost my mind trying to debug this function.\n","# Im just a fucking mess and I cant fix this issue after days and days of trying\n","# and I have to catch up on my other classes\n","\n","train_crf_lstm(sentences_train, tags_train, crf_lstm)             #Train on the full dataset\n","# train_crf_lstm(sentences_train[0:50], tags_train[0:50], crf_lstm)          #Train only the first batch (use this during development/debugging)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["29146\n","32\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:63: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d170908978cf4c96aac39f19644f2971","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=1499.0), HTML(value='')))"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"4omMnnmjJPRD","colab":{"base_uri":"https://localhost:8080/","height":227},"executionInfo":{"status":"error","timestamp":1616004522754,"user_tz":240,"elapsed":467,"user":{"displayName":"Collin Avidano","photoUrl":"","userId":"00144222138809176447"}},"outputId":"b8b3810b-a4c8-459c-97da-b7b7d134dae9"},"source":["crf_lstm.eval()\n","crf_lstm.write_predictions(sentences_test, 'test_pred_cnn_lstm_crf.txt')\n","!wget https://raw.githubusercontent.com/aritter/twitter_nlp/master/data/annotated/wnut16/conlleval.pl\n","!paste test test_pred_cnn_lstm_crf.txt | perl conlleval.pl -d \"\\t\""],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-85cc0320579e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcrf_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcrf_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test_pred_cnn_lstm_crf.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wget https://raw.githubusercontent.com/aritter/twitter_nlp/master/data/annotated/wnut16/conlleval.pl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'paste test test_pred_cnn_lstm_crf.txt | perl conlleval.pl -d \"\\\\t\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'crf_lstm' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"GkjfQ1kRyAKa"},"source":["## Gradescope\n","\n","Gradescope allows you to add multiple files to your submission. Please submit this notebook along with the test set prediction:\n","* test_pred_lstm.txt\n","* test_pred_cnn_lstm.txt\n","* test_pred_cnn_lstm_crf.txt\n","* NER_release.ipynb\n","\n","To download this notebook, go to `File > Download.ipynb`. You can download the predictions from Colab by clicking the folder icon on the left and finding them under Files. \n","\n","Please make sure that you name the files as specified above. You will be able to see the test set accuracy for your predictions. However, the final score will be assigned later based on accuracy and implementation. \n","\n","When submitting the .ipynb notebook, please make sure that all the cells run when executed in order starting from a fresh session. If the code doesn't take too long to run, you can re-run everything with `Runtime -> Restart and run all`\n","\n","You can submit multiple times before the deadline and choose the submission which you want to be graded by going to `Submission History` on gradescope.\n"]},{"cell_type":"code","metadata":{"id":"rhlUIp_OydGz"},"source":[""],"execution_count":null,"outputs":[]}]}