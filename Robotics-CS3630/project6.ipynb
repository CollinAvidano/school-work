{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"project6.ipynb","provenance":[{"file_id":"1WxhraotboF-YO_PMtvn6iXjR8D2pzSxq","timestamp":1586200554689},{"file_id":"1xrZvrlDOUmZAI9G0LoggSMYLWKJsnlrF","timestamp":1585633976086},{"file_id":"1ldmdvJdHj3iPgSA8hraPubBLam-WFtO1","timestamp":1585633673130}],"collapsed_sections":["ytpOz863N0Cw","7HLLS3R3KsUk"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ytpOz863N0Cw"},"source":["# Project 6: Iterative Closest Point\n","\n","Due Date: Monday, April 20, 2020 @ 11:59 P.M.\n","\n","Student Name: Collin Avidano\n","\n","In this project, you will implement the ICP algorithm and use it alongside GTSAM to perform simultaneous localization & mapping (SLAM) on Lidar scans. This is an individual assignment, and you will be held by the Georgia Tech honor code to finish it by yourself. Collaboration at the white board level is allowed."]},{"cell_type":"markdown","metadata":{"id":"q18VQcMT0bGM"},"source":["#Setup\n","\n","In this section, we'll install pip packages, define helper functions, and download the dataset."]},{"cell_type":"code","metadata":{"id":"BamosDIiXIBQ","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1587316295967,"user_tz":240,"elapsed":5908,"user":{"displayName":"Collin Avidano","photoUrl":"","userId":"02884380186597284052"}},"outputId":"4262a7ee-b5f4-4b36-ba40-73a5aa9de656"},"source":["# TODO: Comment this line after running this code cell\n","#!pip install -q gdown pyntcloud plotly gtsam"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 348kB 3.3MB/s \n","\u001b[K     |████████████████████████████████| 7.8MB 11.0MB/s \n","\u001b[?25h"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VLFNdfUNIt8D","colab":{"base_uri":"https://localhost:8080/","height":90},"executionInfo":{"status":"ok","timestamp":1587316307498,"user_tz":240,"elapsed":9281,"user":{"displayName":"Collin Avidano","photoUrl":"","userId":"02884380186597284052"}},"outputId":"b8375aad-c3df-4f20-ce15-8452fe6ae4e9"},"source":["import os\n","import math\n","import gtsam\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import gtsam.utils.plot as gtsam_plot\n","from sklearn.neighbors import NearestNeighbors\n","\n","#!gdown https://drive.google.com/uc?id=1r-A32_tZXwSTMxnemvQrDY7CCpXNG0Ng\n","#!unzip -qo data.zip\n","\n","from data.helpers import *\n","\n","LIDAR_FPATH = \"data/lidar/\"\n","\n","scans_fnames = []\n","for file in sorted(os.listdir(LIDAR_FPATH)):\n","    scans_fnames.append(os.path.join(LIDAR_FPATH, file))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1r-A32_tZXwSTMxnemvQrDY7CCpXNG0Ng\n","To: /content/data.zip\n","195MB [00:01, 184MB/s]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UWTsuOS0poFv"},"source":["Next, load in the datset. This cell finds filenames for all of the point cloud files (.ply) in the dataset."]},{"cell_type":"markdown","metadata":{"id":"KY7-vYBk03i9"},"source":["# Visualization\n","\n","In this section, we'll become aquainted with the dataset."]},{"cell_type":"markdown","metadata":{"id":"BQmor4-PUE-X"},"source":["This dataset is composed of 180 Lidar scans (.ply files) captured by Argo AI, a self-driving car company based in Pittsburgh, PA. These scans were captured over 18 seconds by one of their cars in Miami, which was likely equiped with a Lidar sensor similar to this [one](https://velodynelidar.com/products/hdl-64e/). This 30 second video clip from the car's front camera gives a good intuition of what happens: https://youtu.be/FUDRK_0iEKA. The first 12 seconds, where the car is stationary, are not part of our dataset.\n","\n","It's night-time and the car starts at an offset T-intersection. It waits for a car, three bicyclists, and another car to pass (12 seconds that are not part of our dataset). Then it makes a left turn onto NW 2nd Ave and traveling down the street (18 seconds that is our dataset).\n","\n","In this cell, we read in the first Lidar scan and visualizes it at full resolution (~88,000 points). Use the plot menu to zoom, pan, and rotate around the scene. Then, change the index on `scans_fnames` to see some of the later frames."]},{"cell_type":"code","metadata":{"id":"bidPy9VgWBC-","colab":{"base_uri":"https://localhost:8080/","height":542,"output_embedded_package_id":"1PAH7Q-O6gbHR4mZ-nOiNpHewbfMmppPJ"},"executionInfo":{"status":"ok","timestamp":1587268023667,"user_tz":240,"elapsed":11273,"user":{"displayName":"Collin Avidano","photoUrl":"","userId":"02884380186597284052"}},"outputId":"f74f051a-9f5f-4b4e-9670-b98a29ae9774"},"source":["visualize_clouds(read_ply(scans_fnames[0]), show_grid_lines=True)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"NTFaNRqziiSI"},"source":["This cell reads in the first 20 Lidar scans and visualizes them (as an animation) at a reduced resolution. Due to browser limitations, any additional frames after the first 5 must be rendered at reduced resolutions. Play around with the number of frames loaded by modifying the index on `scans_fnames`."]},{"cell_type":"code","metadata":{"id":"k47ccR13nBEQ","colab":{"base_uri":"https://localhost:8080/","height":542,"output_embedded_package_id":"1s8h3ygKFmCwy03uObTnpvMSuRv1zel3R"},"executionInfo":{"status":"ok","timestamp":1587268036032,"user_tz":240,"elapsed":23617,"user":{"displayName":"Collin Avidano","photoUrl":"","userId":"02884380186597284052"}},"outputId":"342e8cfe-0ac7-46cb-a401-a97d705edfed"},"source":["# the more frames visualized, the lower the resolution of each cloud\n","clouds_subset = read_ply(*scans_fnames[:20], as_animation=True)\n","\n","visualize_clouds_animation(clouds_subset)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"K_nFAm9Y4yF6","colab":{"base_uri":"https://localhost:8080/","height":542,"output_embedded_package_id":"1P8JMr7Aj0Ek6opBX24U4JIGkLQO3NY_Y"},"executionInfo":{"status":"ok","timestamp":1587268058380,"user_tz":240,"elapsed":45950,"user":{"displayName":"Collin Avidano","photoUrl":"","userId":"02884380186597284052"}},"outputId":"73a6d544-426b-4538-f376-fb4eb982e7c7"},"source":["# visualizing the entire sequence at a low resolution\n","clouds_all = read_ply(*scans_fnames, as_animation=True)\n","\n","visualize_clouds_animation(clouds_all)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"jDV7-y-fLYGi"},"source":["# Iterative Closest Point\n","\n","In this section, we'll load in two point clouds and implement the five steps of ICP to align them.\n","\n"]},{"cell_type":"code","metadata":{"id":"WuuRxjEt-obi","colab":{"base_uri":"https://localhost:8080/","height":542,"output_embedded_package_id":"1E8BsI7ORoPDAH3G2OBjt14oFwccw5k4S"},"executionInfo":{"status":"ok","timestamp":1587316354118,"user_tz":240,"elapsed":6099,"user":{"displayName":"Collin Avidano","photoUrl":"","userId":"02884380186597284052"}},"outputId":"6522e323-b5b9-46e9-88e6-8767520c663f"},"source":["# we'll read in the first and sixth clouds\n","clouda = read_ply(scans_fnames[0])[0]\n","cloudb = read_ply(scans_fnames[5])[0]\n","\n","visualize_clouds([clouda, cloudb], show_grid_lines=True)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"YsfVSG7Fj4rI"},"source":["Let's take a moment to talk about the shape of these clouds. Each cloud is a numpy array of shape (3, n), where n is the number of point in the cloud. The first dimension is 3 because each point has an x, y, and z component. Therefore, cloud[0] would be an array of length n that contains the x component of each point in the cloud."]},{"cell_type":"markdown","metadata":{"id":"OCeaDwRGxdlV"},"source":["There are five steps to ICP:\n","1.   Initial transformation\n","2.   Transform cloud\n","3.   Assign closest point pairs\n","4.   Estimate transformation\n","5.   Repeat steps 2-4 for maximum number of iterations or change is very small\n","\n","Let's begin with Step 1: the initial tranformation (no code to implement)\n","\n","The initial transform will be an input to your ICP algorithm, so there is no code to implement here. Below, we describe some methods through which the initial transform is found.\n","\n","As you can see in the visualization of the two clouds, the two clouds are nearly identical. This makes sense since the cloudb was captured 0.1 seconds after clouda. By hovering over the landmarks we expect to stay stationary on the street (such as parked cars along the street), we can see that cloudb is rotated and translated some x amount from clouda. For someone running icp on two clouds, they could use this guess-timate. Here's how this is done at a self-driving company. Tracking landmarks to compose the initial guess is common. Argo AI can (and does) write CNNs to detect and track landmarks (i.e. street signs, buildings, parked cars), and then computes the distance between stationary landmarks.\n","\n","Another method could be using kinematic information of the car. The car know's its heading, velocity, and acceleration, allowing us to use the elapsed time to estimate our transform.\n","\n","Even another method could be centroid of the point clouds. By computing translation between centroida and centroidb, we have half of a guess at the initial transform.\n","\n","Ultimately, the cloud pairs that are being ICP-ed together are captured less than a second apart. It might be possible then to just use the identity transform as the initial guess."]},{"cell_type":"markdown","metadata":{"id":"luA3gl2h68iG"},"source":["**TODO** [8 points]\n","\n","Step 2: Transform cloud\n","\n","Given an input cloud, apply the gtsam.Pose3 transform on each point in the cloud. The recommended approach is convert each point in the point cloud into homogeneous points and apply a homogeneous transformation to each point. Using numpy, this can be done with no loops.\n","\n","Hint: Look at gtsam.Pose3's documentation for the `matrix()` function to get the homogeneous transform."]},{"cell_type":"code","metadata":{"id":"lCvWLZZr1JTY"},"source":["def transform_cloud(bTa, clouda):\n","    \"\"\"Transforms each point in a cloud\n","    given a gtsam.Pose3 transform.\n","\n","    Args:\n","        bTa (gtsam.Pose3): the transform used on each pt in the cloud\n","        clouda (ndarray):  the cloud being transformed\n","\n","    Ret:\n","        ndarray: the transformed cloud\n","    \"\"\"\n","\n","    # bTa world to a transform\n","    # print(bTa.matrix())\n","    \n","    clouda_m = np.concatenate(( clouda, np.full((1, clouda.shape[1]), 1) )) \n","    transformeda = np.matmul(bTa.matrix(), clouda_m)\n","    carta = transformeda[0:3,:] / transformeda[3,:] \n","    return carta "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UshWg4peMcYO"},"source":["**TODO** [8 points]\n","\n","Step 3: Assign closest point pairs\n","\n","For each point in clouda, find the closest (euclidean-wise) point in cloudb and form a pair. Return a cloud shaped like clouda that has been rearranged to form closest pairs index-wise between points in clouda and points in rearranged cloudb.\n","\n","Note: we have imported scipy's `NearestNeighbors`. Look at the documentation and use it in your implementation."]},{"cell_type":"code","metadata":{"id":"QwCUoO9gMoIK"},"source":["def assign_closest_pairs(clouda, cloudb):\n","    \"\"\"Returns a rearranged version of cloudb,\n","    where index-wise corresponding points in\n","    clouda and rearranged cloudb are closest\n","    euclidean distance.\n","\n","    Note: Don't modify clouda or cloudb here.\n","\n","    Args:\n","        clouda (ndarray): point cloud A\n","        cloudb (ndarray): point cloud B\n","\n","    Ret:\n","        ndarray: rearranged cloudb\n","    \"\"\"\n","    # Can I have a hug. My stress is just really bad ever since this all began. Like I know its that way for everyone thought so I hope you all are doing well.\n","\n","    neigh = NearestNeighbors(n_neighbors=1)\n","    neigh.fit(cloudb.T) # keep it aligned with the example code from docs where a point is a row\n","    distances, indicies = neigh.kneighbors(clouda.T)\n","    \n","    cloudb_mod = cloudb[:, indicies.flatten()] # use the rearranged cloudb indicies (2nd column of the indicies) coming out of kneighbors to access those columns in the original cloudb forming a reorganized version\n","   \n","    return cloudb_mod"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DkVK2YOqd2IK"},"source":["Step 4: Estimate transform (This step is given by the TAs.)\n","\n","Given clouda and cloudb, this function will tell you the transform to apply on clouda to get closer to cloudb."]},{"cell_type":"code","metadata":{"id":"D7l-Se95arwP"},"source":["def estimate_transform(clouda, cloudb):\n","    \"\"\"Estimate the transform from clouda to\n","    cloudb. Returns a gtsam.Pose3 object.\n","\n","    Args:\n","        clouda (ndarray): point cloud A\n","        cloudb (ndarray): point cloud B\n","    \"\"\"\n","    if clouda.shape != cloudb.shape and clouda.shape[1] < 3:\n","        return None\n","    \n","    centroida = np.average(clouda, axis=1)\n","    centroidb = np.average(cloudb, axis=1)\n","\n","    clouda_prime = clouda - centroida[:, np.newaxis]\n","    cloudb_prime = cloudb - centroidb[:, np.newaxis]\n","    H = np.sum(clouda_prime.T[:,:,None]*cloudb_prime.T[:,None], axis=0)\n","\n","    aRb = gtsam.Rot3.ClosestTo(H)\n","    rot_centroidb = aRb.rotate(gtsam.Point3(centroidb))\n","    atb = gtsam.Point3(centroida - np.array([rot_centroidb.x(), rot_centroidb.y(), rot_centroidb.z()]))\n","\n","    return gtsam.Pose3(aRb, atb).inverse()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A__i0XTTaXVH"},"source":["**TODO** [9 points]\n","\n","Step 5: Repeat steps 2-4 for maximum number of iterations or change is very small\n","\n","Putting it all together. Using the four functions you've written, implement the complete ICP algorithm. Per each iteration of ICP, give transformed clouda and cloudb as inputs to `assign_closest_pairs()`. The first output, `bTa`, is a gtsam.Pose3 object, which is a transform describing how to transform clouda to align with cloudb. The second output, `icp_series`, lets you visualize each iteration of your ICP algorithm. The format of `icp_series` is an list of lists.\n","\n","Example: `[[clouda_iter1, cloudb_iter1], [clouda_iter2, cloudb_iter2], [clouda_iter3, cloudb_iter3], ...]`"]},{"cell_type":"code","metadata":{"id":"9H2rtP5fr4Ab"},"source":["def icp(clouda, cloudb, initial_transform=gtsam.Pose3(), max_iterations=25):\n","    \"\"\"Runs ICP on two clouds by calling\n","    all five steps implemented above.\n","    Iterates until close enough or max\n","    iterations.\n","\n","    Returns a series of intermediate clouds\n","    for visualization purposes.\n","\n","    Args:\n","        clouda (ndarray):                point cloud A\n","        cloudb (ndarray):                point cloud B\n","        initial_transform (gtsam.Pose3): the initial estimate of transform between clouda and cloudb (step 1 of icp)\n","        max_iterations (int):            maximum iters of ICP to run before breaking\n","\n","    Ret:\n","        bTa (gtsam.Pose3): the final transform\n","        icp_series (list): visualized icp for debugging\n","    \"\"\"\n","    epsilon = 1e-2\n","\n","    #.1   Initial transformation\n","    current_transform = initial_transform\n","    last_transform = None\n","\n","    icp_series = []\n","\n","    for iteration in range(max_iterations):\n","      #print(\"iteration: \" + str(iteration))\n","      \n","      #2.   Transform cloud\n","      clouda_mod = transform_cloud(current_transform, clouda)\n","\n","      #3.   Assign closest point pairs\n","      cloudb_mod = assign_closest_pairs(clouda_mod, cloudb)\n","      \n","      icp_series.append([clouda_mod,cloudb_mod])\n","      \n","\n","      #     Save last transform for step 5\n","      last_transform = current_transform\n","\n","      #4.   Estimate transformation\n","      current_transform = current_transform.compose(estimate_transform(clouda_mod, cloudb_mod))\n","\n","      #5.   Repeat steps 2-4 for maximum number of iterations or change is very small\n","      if current_transform.equals(last_transform,epsilon):\n","        break\n","\n","    \n","    bTa = current_transform\n","    return bTa, icp_series"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4TSSQoD1dr1-"},"source":["The animation shows how clouda has moved after each iteration of ICP. You should see stationary landmarks, like walls and parked cars, converge onto each other."]},{"cell_type":"code","metadata":{"id":"uQQ18QxLccZF","colab":{"base_uri":"https://localhost:8080/","height":669,"output_embedded_package_id":"1peRVuzgd91eTtvP89Ww9SqC2V2kkn-H9"},"executionInfo":{"status":"ok","timestamp":1587333834467,"user_tz":240,"elapsed":22494,"user":{"displayName":"Collin Avidano","photoUrl":"","userId":"02884380186597284052"}},"outputId":"7463f0fb-4587-43b0-f3ec-eb36cfb8835d"},"source":["aTb, icp_series = icp(clouda, cloudb)\n","print(aTb)\n","visualize_clouds_animation(icp_series, speed=400, show_grid_lines=True)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"_rwsCNFY6EKh"},"source":["ICP is a computationally intense algorithm and we plan to run it between each cloud pair in our 180 clouds dataset. Use the python profiler to identify the computationally expensive subroutines in your algorithm and use numpy to reduce your runtime. The TAs get ~6.5 seconds."]},{"cell_type":"code","metadata":{"id":"QVzRHJzD6DLm","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1587333685959,"user_tz":240,"elapsed":10024,"user":{"displayName":"Collin Avidano","photoUrl":"","userId":"02884380186597284052"}},"outputId":"99b223d5-6549-4cf6-d917-43c58517f597"},"source":["import cProfile\n","cProfile.run('icp(clouda, cloudb)')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["         13554 function calls (13429 primitive calls) in 9.652 seconds\n","\n","   Ordered by: standard name\n","\n","   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n","       50    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(atleast_2d)\n","       50    0.000    0.000    0.047    0.001 <__array_function__ internals>:2(average)\n","       75    0.000    0.000    0.030    0.000 <__array_function__ internals>:2(concatenate)\n","       25    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(copy)\n","       50    0.000    0.000    0.007    0.000 <__array_function__ internals>:2(copyto)\n","      100    0.000    0.000    0.130    0.001 <__array_function__ internals>:2(sum)\n","       50    0.000    0.000    0.011    0.000 <__array_function__ internals>:2(vstack)\n","      100    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:416(parent)\n","      100    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:997(_handle_fromlist)\n","       25    0.050    0.002    0.078    0.003 <ipython-input-10-be93515679ee>:1(transform_cloud)\n","       25    0.060    0.002    9.244    0.370 <ipython-input-11-f19939f3e714>:1(assign_closest_pairs)\n","       25    0.158    0.006    0.318    0.013 <ipython-input-12-ef42fa6c53f3>:1(estimate_transform)\n","        1    0.010    0.010    9.651    9.651 <ipython-input-37-1a2943da7f89>:1(icp)\n","        1    0.002    0.002    9.652    9.652 <string>:1(<module>)\n","       50    0.000    0.000    0.000    0.000 __init__.py:786(gen_even_slices)\n","      150    0.000    0.000    0.052    0.000 _asarray.py:16(asarray)\n","      225    0.000    0.000    0.000    0.000 _asarray.py:88(asanyarray)\n","       25    0.000    0.000    3.437    0.137 _base.py:1155(fit)\n","       25    0.000    0.000    0.001    0.000 _base.py:292(__init__)\n","       50    0.000    0.000    0.000    0.000 _base.py:307(_check_algorithm_metric)\n","       25    3.392    0.136    3.437    0.137 _base.py:349(_fit)\n","       25    0.000    0.000    5.705    0.228 _base.py:485(_tree_query_parallel_helper)\n","       25    0.001    0.000    5.742    0.230 _base.py:532(kneighbors)\n","       50    0.000    0.000    0.000    0.000 _base.py:662(<genexpr>)\n","       75    0.000    0.000    0.000    0.000 _config.py:13(get_config)\n","       50    0.002    0.000    0.046    0.001 _methods.py:134(_mean)\n","       50    0.000    0.000    0.000    0.000 _methods.py:50(_count_reduce_items)\n","       50    0.000    0.000    0.000    0.000 _parallel_backends.py:138(retrieval_context)\n","       25    0.000    0.000    0.000    0.000 _parallel_backends.py:201(effective_n_jobs)\n","       25    0.000    0.000    5.707    0.228 _parallel_backends.py:207(apply_async)\n","       25    0.000    0.000    0.001    0.000 _parallel_backends.py:214(get_nested_backend)\n","       25    0.000    0.000    0.000    0.000 _parallel_backends.py:228(effective_n_jobs)\n","       75    0.000    0.000    0.000    0.000 _parallel_backends.py:281(__init__)\n","      125    0.000    0.000    0.000    0.000 _parallel_backends.py:37(__init__)\n","       25    0.000    0.000    0.000    0.000 _parallel_backends.py:390(configure)\n","       25    0.000    0.000    0.000    0.000 _parallel_backends.py:521(effective_n_jobs)\n","       25    0.000    0.000    5.706    0.228 _parallel_backends.py:587(__init__)\n","       25    0.000    0.000    0.000    0.000 _parallel_backends.py:592(get)\n","       25    0.000    0.000    0.000    0.000 _parallel_backends.py:630(__init__)\n","       25    0.000    0.000    0.000    0.000 _parallel_backends.py:71(configure)\n","       25    0.000    0.000    0.000    0.000 _parallel_backends.py:81(start_call)\n","       25    0.000    0.000    0.000    0.000 _parallel_backends.py:84(stop_call)\n","       25    0.000    0.000    0.000    0.000 _parallel_backends.py:87(terminate)\n","       50    0.000    0.000    0.000    0.000 _parallel_backends.py:90(compute_batch_size)\n","       25    0.000    0.000    0.000    0.000 _parallel_backends.py:94(batch_completed)\n","       25    0.000    0.000    0.001    0.000 _unsupervised.py:108(__init__)\n","      150    0.001    0.000    0.001    0.000 _weakrefset.py:70(__contains__)\n","      125    0.001    0.000    0.001    0.000 abc.py:180(__instancecheck__)\n","      125    0.000    0.000    0.000    0.000 base.py:1192(isspmatrix)\n","       25    0.000    0.000    0.000    0.000 context.py:232(get_context)\n","       25    0.000    0.000    0.000    0.000 contextlib.py:157(helper)\n","       25    0.000    0.000    0.000    0.000 contextlib.py:59(__init__)\n","       25    0.000    0.000    0.000    0.000 contextlib.py:79(__enter__)\n","       25    0.000    0.000    0.000    0.000 contextlib.py:85(__exit__)\n","       25    0.000    0.000    0.000    0.000 disk.py:41(memstr_to_bytes)\n","       75    0.001    0.000    0.020    0.000 extmath.py:681(_safe_accumulator_op)\n","      100    0.000    0.000    0.000    0.000 fromnumeric.py:2087(_sum_dispatcher)\n","      100    0.001    0.000    0.130    0.001 fromnumeric.py:2092(sum)\n","      100    0.001    0.000    0.129    0.001 fromnumeric.py:73(_wrapreduction)\n","      100    0.000    0.000    0.000    0.000 fromnumeric.py:74(<dictcomp>)\n","       50    0.000    0.000    0.000    0.000 function_base.py:289(_average_dispatcher)\n","       50    0.000    0.000    0.047    0.001 function_base.py:293(average)\n","       25    0.000    0.000    0.000    0.000 function_base.py:726(_copy_dispatcher)\n","       25    0.000    0.000    0.000    0.000 function_base.py:730(copy)\n","       25    0.000    0.000    0.000    0.000 functools.py:44(update_wrapper)\n","       25    0.000    0.000    0.000    0.000 functools.py:74(wraps)\n","       25    0.000    0.000    0.000    0.000 inspect.py:73(isclass)\n","       25    0.000    0.000    0.000    0.000 logger.py:23(_squeeze_time)\n","       25    0.000    0.000    0.000    0.000 logger.py:39(short_format_time)\n","       50    0.000    0.000    0.000    0.000 multiarray.py:1043(copyto)\n","       75    0.000    0.000    0.000    0.000 multiarray.py:145(concatenate)\n","       50    0.000    0.000    0.007    0.000 numeric.py:283(full)\n","      250    0.000    0.000    0.001    0.000 numerictypes.py:293(issubclass_)\n","      125    0.000    0.000    0.001    0.000 numerictypes.py:365(issubdtype)\n","       25    0.000    0.000    0.000    0.000 parallel.py:179(__init__)\n","       25    0.000    0.000    0.000    0.000 parallel.py:211(__enter__)\n","       25    0.000    0.000    0.000    0.000 parallel.py:214(__exit__)\n","       25    0.000    0.000    0.000    0.000 parallel.py:217(unregister)\n","       25    0.000    0.000    0.000    0.000 parallel.py:240(__init__)\n","       25    0.000    0.000    5.706    0.228 parallel.py:251(__call__)\n","       25    0.000    0.000    5.705    0.228 parallel.py:255(<listcomp>)\n","       75    0.000    0.000    0.000    0.000 parallel.py:258(__len__)\n","       25    0.000    0.000    0.001    0.000 parallel.py:295(delayed)\n","       25    0.000    0.000    0.000    0.000 parallel.py:305(delayed_function)\n","       25    0.000    0.000    0.000    0.000 parallel.py:326(__init__)\n","       25    0.000    0.000    0.000    0.000 parallel.py:331(__call__)\n","       25    0.000    0.000    0.001    0.000 parallel.py:366(effective_n_jobs)\n","       25    0.001    0.000    0.002    0.000 parallel.py:616(__init__)\n","    50/25    0.000    0.000    0.001    0.000 parallel.py:707(_initialize_backend)\n","       25    0.000    0.000    0.000    0.000 parallel.py:732(_terminate_backend)\n","       25    0.000    0.000    5.707    0.228 parallel.py:736(_dispatch)\n","       50    0.001    0.000    5.711    0.114 parallel.py:773(dispatch_one_batch)\n","       75    0.000    0.000    0.001    0.000 parallel.py:81(get_active_backend)\n","       50    0.000    0.000    0.000    0.000 parallel.py:838(_print)\n","       25    0.000    0.000    0.000    0.000 parallel.py:851(print_progress)\n","       25    0.000    0.000    0.000    0.000 parallel.py:894(retrieve)\n","       25    0.001    0.000    5.713    0.229 parallel.py:942(__call__)\n","       25    0.000    0.000    0.000    0.000 queue.py:115(put)\n","       75    0.000    0.000    0.001    0.000 queue.py:147(get)\n","       25    0.000    0.000    0.000    0.000 queue.py:199(_init)\n","       75    0.000    0.000    0.000    0.000 queue.py:202(_qsize)\n","       25    0.000    0.000    0.000    0.000 queue.py:206(_put)\n","       25    0.000    0.000    0.000    0.000 queue.py:210(_get)\n","       25    0.000    0.000    0.001    0.000 queue.py:27(__init__)\n","       50    0.000    0.000    0.000    0.000 shape_base.py:209(_arrays_for_stack_dispatcher)\n","       50    0.000    0.000    0.000    0.000 shape_base.py:220(_vhstack_dispatcher)\n","       50    0.000    0.000    0.011    0.000 shape_base.py:224(vstack)\n","       50    0.000    0.000    0.000    0.000 shape_base.py:79(_atleast_2d_dispatcher)\n","       50    0.000    0.000    0.000    0.000 shape_base.py:83(atleast_2d)\n","       25    0.000    0.000    0.000    0.000 stride_tricks.py:21(__init__)\n","       25    0.000    0.000    0.000    0.000 stride_tricks.py:26(_maybe_view_as_subclass)\n","       25    0.001    0.000    0.001    0.000 stride_tricks.py:39(as_strided)\n","       75    0.000    0.000    0.000    0.000 threading.py:215(__init__)\n","      100    0.000    0.000    0.000    0.000 threading.py:239(__enter__)\n","      100    0.000    0.000    0.000    0.000 threading.py:242(__exit__)\n","       50    0.000    0.000    0.000    0.000 threading.py:254(_is_owned)\n","       50    0.000    0.000    0.000    0.000 threading.py:334(notify)\n","       25    0.000    0.000    0.000    0.000 threading.py:74(RLock)\n","       75    0.001    0.000    0.002    0.000 validation.py:136(_num_samples)\n","       75    0.000    0.000    0.000    0.000 validation.py:343(_ensure_no_complex_data)\n","       75    0.003    0.000    0.052    0.001 validation.py:350(check_array)\n","       75    0.003    0.000    0.024    0.000 validation.py:37(_assert_all_finite)\n","       25    0.000    0.000    0.001    0.000 validation.py:904(check_is_fitted)\n","       25    0.000    0.000    0.000    0.000 validation.py:963(<listcomp>)\n","       50    0.000    0.000    0.001    0.000 version.py:302(__init__)\n","       50    0.000    0.000    0.001    0.000 version.py:307(parse)\n","       50    0.000    0.000    0.000    0.000 version.py:312(<listcomp>)\n","       25    0.000    0.000    0.000    0.000 version.py:331(_cmp)\n","       25    0.000    0.000    0.000    0.000 version.py:51(__lt__)\n","       75    0.000    0.000    0.001    0.000 warnings.py:143(simplefilter)\n","       75    0.000    0.000    0.001    0.000 warnings.py:159(_add_filter)\n","       75    0.000    0.000    0.000    0.000 warnings.py:428(__init__)\n","       75    0.001    0.000    0.001    0.000 warnings.py:449(__enter__)\n","       75    0.000    0.000    0.000    0.000 warnings.py:468(__exit__)\n","       25    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n","      225    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\n","      100    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\n","        1    0.000    0.000    9.652    9.652 {built-in method builtins.exec}\n","      575    0.001    0.000    0.001    0.000 {built-in method builtins.getattr}\n","      775    0.001    0.000    0.001    0.000 {built-in method builtins.hasattr}\n","      900    0.001    0.000    0.002    0.000 {built-in method builtins.isinstance}\n","      475    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\n","       25    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n","      550    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n","       50    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n","       50    0.000    0.000    0.000    0.000 {built-in method builtins.next}\n","      125    0.000    0.000    0.000    0.000 {built-in method builtins.setattr}\n","       25    0.000    0.000    0.000    0.000 {built-in method builtins.vars}\n","      475    0.052    0.000    0.052    0.000 {built-in method numpy.array}\n","  400/300    0.038    0.000    0.215    0.001 {built-in method numpy.core._multiarray_umath.implement_array_function}\n","       50    0.000    0.000    0.000    0.000 {built-in method numpy.empty}\n","      100    0.000    0.000    0.000    0.000 {built-in method time.time}\n","       25    0.001    0.000    0.001    0.000 {gtsam.gtsam.ClosestTo}\n","      100    0.000    0.000    0.000    0.000 {method '__enter__' of '_thread.lock' objects}\n","      100    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}\n","       50    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n","       25    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n","       75    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n","       25    0.000    0.000    0.000    0.000 {method 'compose' of 'gtsam.gtsam.Pose3' objects}\n","       75    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}\n","        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n","      350    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\n","       25    0.000    0.000    0.000    0.000 {method 'equals' of 'gtsam.gtsam.Pose3' objects}\n","       25    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\n","       25    0.004    0.000    0.004    0.000 {method 'flatten' of 'numpy.ndarray' objects}\n","       25    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n","      100    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\n","       25    0.000    0.000    0.000    0.000 {method 'inverse' of 'gtsam.gtsam.Pose3' objects}\n","      100    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n","       25    0.002    0.000    0.004    0.000 {method 'matrix' of 'gtsam.gtsam.Pose3' objects}\n","       50    0.000    0.000    0.046    0.001 {method 'mean' of 'numpy.ndarray' objects}\n","       25    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}\n","       25    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}\n","       25    0.000    0.000    0.000    0.000 {method 'popleft' of 'collections.deque' objects}\n","       25    5.672    0.227    5.705    0.228 {method 'query' of 'sklearn.neighbors._kd_tree.BinaryTree' objects}\n","      150    0.172    0.001    0.172    0.001 {method 'reduce' of 'numpy.ufunc' objects}\n","       75    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\n","       25    0.000    0.000    0.000    0.000 {method 'rotate' of 'gtsam.gtsam.Rot3' objects}\n","      100    0.000    0.000    0.000    0.000 {method 'rpartition' of 'str' objects}\n","       50    0.000    0.000    0.000    0.000 {method 'split' of '_sre.SRE_Pattern' objects}\n","      100    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\n","       25    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}\n","       25    0.000    0.000    0.000    0.000 {method 'x' of 'gtsam.gtsam.Point3' objects}\n","       25    0.000    0.000    0.000    0.000 {method 'y' of 'gtsam.gtsam.Point3' objects}\n","       25    0.000    0.000    0.000    0.000 {method 'z' of 'gtsam.gtsam.Point3' objects}\n","\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"q8ZZeNbi5ceq"},"source":["These unit tests will verify the basic functionality of the functions you've implemented in this section. Keep in mind that these are not exhaustive."]},{"cell_type":"code","metadata":{"id":"Eu3RtYPF5bHx","colab":{"base_uri":"https://localhost:8080/","height":181},"executionInfo":{"status":"ok","timestamp":1587333811958,"user_tz":240,"elapsed":98802,"user":{"displayName":"Collin Avidano","photoUrl":"","userId":"02884380186597284052"}},"outputId":"3bd24846-f644-455e-c6ad-54f7856980d1"},"source":["import unittest\n","\n","class TestICP(unittest.TestCase):\n","\n","    def setUp(self):\n","        self.testclouda = np.array([[1], [1], [1]])\n","        self.testcloudb = np.array([[2, 10], [1, 1], [1, 1]])\n","        self.testcloudc = np.array([[2], [1], [1]])\n","        self.testbTa = gtsam.Pose3(gtsam.Rot3(), gtsam.Point3(1, 0, 0))\n","        self.testcloudd = np.array([[0, 20, 10], [0, 10, 20], [0, 0, 0]])\n","        self.testcloude = np.array([[10, 30, 20], [10, 20, 30], [0, 0, 0]])\n","\n","    def test_assign_closest_pairs1(self):\n","        expected = (3, 1)\n","        actual = assign_closest_pairs(self.testclouda, self.testcloudb).shape\n","        self.assertEqual(expected, actual)\n","\n","    def test_assign_closest_pairs2(self):\n","        expected = 2\n","        actual = assign_closest_pairs(self.testclouda, self.testcloudb)[0][0]\n","        self.assertEqual(expected, actual)\n","\n","    def test_estimate_transform1(self):\n","        expected = 1\n","        actual = estimate_transform(self.testclouda, self.testcloudc).x()\n","        self.assertEqual(expected, actual)\n","\n","    def test_estimate_transform2(self):\n","        expected = 10\n","        actual = estimate_transform(self.testcloudd, self.testcloude).x()\n","        self.assertAlmostEqual(expected, actual, places=7)\n","        actua2 = estimate_transform(self.testcloudd, self.testcloude).y()\n","        self.assertAlmostEqual(expected, actua2, places=7)\n","\n","    def test_transform_cloud1(self):\n","        expected = 2\n","        actual = transform_cloud(self.testbTa, self.testclouda)[0][0]\n","        self.assertEqual(expected, actual)\n","\n","    def test_icp1(self):\n","        ret = icp(self.testclouda, self.testcloudb)\n","        expected1 = type(gtsam.Pose3())\n","        actual1 = type(ret[0])\n","        self.assertEqual(expected1, actual1)\n","        expected2 = type([])\n","        actual2 = type(ret[1])\n","        self.assertEqual(expected2, actual2)\n","        expected3 = type([])\n","        actual3 = type(ret[1][0])\n","        self.assertEqual(expected3, actual3)\n","\n","    def test_icp2(self):\n","        expected = 1\n","        actual = icp(self.testclouda, self.testcloudb)[0].x()\n","        self.assertEqual(expected, actual)\n","\n","    def test_icp3(self):\n","        expected = 1\n","        actual = icp(self.testclouda, self.testcloudc)[0].x()\n","        self.assertEqual(expected, actual)\n","\n","if __name__ == \"__main__\":\n","    unittest.main(argv=['first-arg-is-ignored'], exit=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["......"],"name":"stdout"},{"output_type":"stream","text":["."],"name":"stderr"},{"output_type":"stream","text":[".\n"," Done\n","......"],"name":"stdout"},{"output_type":"stream","text":["........."],"name":"stderr"},{"output_type":"stream","text":[".\n"," Done\n"],"name":"stdout"},{"output_type":"stream","text":["\n","----------------------------------------------------------------------\n","Ran 10 tests in 98.542s\n","\n","OK\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"O1IqCZ1ZvGzt"},"source":["# Factor Graph\n","\n","In this section, we'll build a factor graph to estimate the pose of our vechicle using the transforms our ICP algorithm gives us between frames. These ICP transforms are the factors that tie the pose variables together."]},{"cell_type":"markdown","metadata":{"id":"MCswJeHPxY1S"},"source":["We will be using GTSAM to construct the factor graph as well as perform a optimization for the pose of the car as it travels down the street. Let's start with a simple example first. Recall from PoseSLAM describe in the LIDAR slides how we could add a factor (aka constraint) between two state variables. When we revisited a state, we could add a loop closure. Since the car in our dataset never revisits a previous pose, there is not loop closure. Here is that example from the slides copied here. Note how the graph is initialized and how factors are added."]},{"cell_type":"code","metadata":{"id":"g6UW4guRAC62","colab":{"base_uri":"https://localhost:8080/","height":502},"executionInfo":{"status":"ok","timestamp":1587316446733,"user_tz":240,"elapsed":513,"user":{"displayName":"Collin Avidano","photoUrl":"","userId":"02884380186597284052"}},"outputId":"ab5d4162-295c-4e7a-b706-ecae23baad72"},"source":["# # Factor graph example \n","\n","# Helper function to create a pose\n","def vector3(x, y, z):\n","    \"\"\"Create 3d double numpy array.\"\"\"\n","    return np.array([x, y, z], dtype=np.float)\n","\n","# Create noise model\n","priorNoise = gtsam.noiseModel_Diagonal.Sigmas(vector3(0.3, 0.3, 0.1))\n","model = gtsam.noiseModel_Diagonal.Sigmas(vector3(0.2, 0.2, 0.1))\n","\n","# Instantiate the factor graph\n","example_graph = gtsam.NonlinearFactorGraph()\n","\n","# Adding a prior on the first pose\n","example_graph.add(gtsam.PriorFactorPose2(1, gtsam.Pose2(0, 0, 0), priorNoise))\n","\n","# Create odometry (Between) factors between consecutive poses\n","example_graph.add(gtsam.BetweenFactorPose2( 1, 2, gtsam.Pose2(2, 0, 0), model)) \n","example_graph.add(gtsam.BetweenFactorPose2(2, 3, gtsam.Pose2(2, 0, math.pi / 2), model)) \n","example_graph.add(gtsam.BetweenFactorPose2(3, 4, gtsam.Pose2(2, 0, math.pi / 2), model)) \n","example_graph.add(gtsam.BetweenFactorPose2(4, 5, gtsam.Pose2(2, 0, math.pi / 2), model)) \n","\n","# Add the loop closure constraint\n","example_graph.add(gtsam.BetweenFactorPose2(5, 2, gtsam.Pose2(2, 0, math.pi / 2), model)) \n","\n","# Create the initial estimate\n","example_initial_estimate = gtsam.Values()\n","example_initial_estimate.insert(1, gtsam.Pose2(0.5, 0.0, 0.2))\n","example_initial_estimate.insert(2, gtsam.Pose2(2.3, 0.1, -0.2))\n","example_initial_estimate.insert(3, gtsam.Pose2(4.1, 0.1, math.pi / 2))\n","example_initial_estimate.insert(4, gtsam.Pose2(4.0, 2.0, math.pi))\n","example_initial_estimate.insert(5, gtsam.Pose2(2.1, 2.1, -math.pi / 2))\n","\n","# 4. Optimize the initial values using a Gauss-Newton nonlinear optimizer\n","ex_parameters = gtsam.GaussNewtonParams()\n","ex_parameters.setRelativeErrorTol(1e-5)\n","ex_parameters.setMaxIterations(100)\n","ex_optimizer = gtsam.GaussNewtonOptimizer(example_graph, example_initial_estimate, ex_parameters)\n","ex_result = ex_optimizer.optimize()\n","print(\"Final Result:\\n{}\".format(ex_result))\n","\n","# Plot your graph\n","marginals = gtsam.Marginals(example_graph, ex_result)\n","fig = plt.figure(0)\n","for i in range(1, 6):\n","    gtsam_plot.plot_pose2(0, ex_result.atPose2(i), 0.5, marginals.marginalCovariance(i))\n","\n","plt.axis('equal')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Final Result:\n","Values with 5 values:\n","Value 1: (N5gtsam5Pose2E) (-4.57314e-23, -1.00623e-19, -4.65026e-20)\n","\n","Value 2: (N5gtsam5Pose2E) (2, -2.3835e-19, -7.06444e-20)\n","\n","Value 3: (N5gtsam5Pose2E) (4, -3.42174e-11, 1.5708)\n","\n","Value 4: (N5gtsam5Pose2E) (4, 2, 3.14159)\n","\n","Value 5: (N5gtsam5Pose2E) (2, 2, -1.5708)\n","\n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"8c_QZE3hSWue"},"source":["**TODO** [25 points]\n","\n","You will be using your ICP implementation here to find the transform between two subsequent clouds. These transforms become the factors between pose variables in the graph. So, you will need to go through all the point clouds and run icp pair-wise to find the relative movement of the car. With these transformation, create a factor representing the transform between the pose variables.\n","\n","We talked about how loop closure helps us consolidate conflicting data into a better global estimate. Unfortunately, our car does not perform a loop closure. So, our graph would just be a long series of poses connected by icp-returned transforms. However, our lidar scans are noisy, which means that our icp-returned transforms are not perfect either. This ultimately results in incorrect vehicle poses and overall map. One way that we can augment our graph is through \"skipping\". We simply run ICP between every other cloud, and add these skip connections into the graph. You can basically perform ICP between two non-consecutive point clouds and add that transform as a factor in the factor graph."]},{"cell_type":"code","metadata":{"id":"Yus6fnRtSbod"},"source":["def populate_factor_graph(graph, initial_estimates, initial_pose, clouds):\n","    \"\"\"Populates a gtsam.NonlinearFactorGraph with\n","    factors between state variables. Populates\n","    initial_estimates for state variables as well.\n","\n","    Args:\n","        graph (gtsam.NonlinearFactorGraph): the factor graph populated with ICP constraints\n","        initial_estimates (gtsam.Values):   the populated estimates for vehicle poses\n","        initial_pose (gtsam.Pose3):         the starting pose for the estimates in world coordinates\n","        clouds (np.ndarray):                the numpy array with all our point clouds\n","    \"\"\"\n","    ICP_NOISE = gtsam.noiseModel_Diagonal.Sigmas(np.array([1e-6, 1e-6, 1e-6, 1e-4, 1e-4, 1e-4]))\n","    factor_pose = initial_pose\n","\n","    # Add ICP Factors between each pair of clouds\n","    prev_T = gtsam.Pose3()\n","    for i in range(len(clouds) - 1):\n","        # TODO: Run ICP between clouds (hint: use inital_tranform argument)\n","        T, icp_series = icp(clouds[i], clouds[i+1], initial_transform=prev_T)\n","        #prev_T = T\n","\n","        # TODO: Set T to its inverse: use `gtsam.Pose3.inverse()`\n","        T = T.inverse()\n","        prev_T = T\n","\n","        # TODO: Add a `gtsam.BetweenFactorPose3()` to the graph\n","        graph.add( gtsam.BetweenFactorPose3( i, i + 1, T, ICP_NOISE ) )\n","\n","        factor_pose = factor_pose.compose(T)\n","        initial_estimates.insert(i+1, factor_pose)\n","        print(\".\", end=\"\")\n","\n","    # Add skip connections between every other frame\n","    prev_T = gtsam.Pose3()\n","    for i in range(0, len(clouds) - 2, 2):\n","        # TODO: Run ICP between clouds (hint: use inital_tranform argument)\n","        T, icp_series = icp(clouds[i], clouds[i+2], initial_transform=prev_T)\n","        #prev_T = T\n","\n","        # TODO: Set T to its inverse: use `gtsam.Pose3.inverse()`\n","        T = T.inverse()\n","        prev_T = T\n","\n","        # TODO: Add a `gtsam.BetweenFactorPose3()` to the graph\n","        graph.add( gtsam.BetweenFactorPose3( i, i + 2, T, ICP_NOISE ) )\n","\n","        print(\".\", end=\"\")\n","\n","    print(\"\\n Done\")\n","    return graph, initial_estimates"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G3Zt28AiSl9S"},"source":["The real power of GTSAM will show here. In five lines, we'll setup a Gauss Newton nonlinear optimizer and optimize for the vehicle's poses in world coordinates.\n","\n","Note: This cell runs your ICP implementation 180 times. If you've implemented your ICP similarly to the TAs, expect this cell to take 2 minutes. If you're missing the `initial_transform` argument for icp, it may take ~1 hour."]},{"cell_type":"code","metadata":{"id":"LPsfUC33Si7p","colab":{"base_uri":"https://localhost:8080/","height":73},"executionInfo":{"status":"ok","timestamp":1587335645832,"user_tz":240,"elapsed":1671481,"user":{"displayName":"Collin Avidano","photoUrl":"","userId":"02884380186597284052"}},"outputId":"119f5673-284e-4196-e0ad-9ec6b0146f61"},"source":["# load in all clouds in our dataset\n","clouds = read_ply(*scans_fnames)\n","\n","# Setting up our factor graph\n","graph = gtsam.NonlinearFactorGraph()\n","initial_estimates = gtsam.Values()\n","\n","# We get the initial pose of the car from Argo AI's dataset, and we add it to the graph as such\n","PRIOR_NOISE = gtsam.noiseModel_Diagonal.Sigmas(np.array([1e-6, 1e-6, 1e-6, 1e-4, 1e-4, 1e-4]))\n","initial_pose = gtsam.Pose3(gtsam.Rot3(0.9982740, -0.0572837,  0.0129474, 0.0575611,  0.9980955, -0.0221840, -0.0116519,  0.0228910,  0.9996701),\n","                           gtsam.Point3(-263.9464864482589, 2467.3015467381383, -19.374652610889633))\n","graph.add(gtsam.PriorFactorPose3(0, initial_pose, PRIOR_NOISE))\n","initial_estimates.insert(0, initial_pose)\n","\n","# We'll use your function to populate the factor graph\n","graph, initial_estimates = populate_factor_graph(graph, initial_estimates, initial_pose, clouds)\n","\n","# Now optimize for the states\n","parameters = gtsam.GaussNewtonParams()\n","parameters.setRelativeErrorTol(1e-5)\n","parameters.setMaxIterations(100)\n","optimizer = gtsam.GaussNewtonOptimizer(graph, initial_estimates, parameters)\n","result = optimizer.optimize()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["............................................................................................................................................................................................................................................................................\n"," Done\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XFRK6Rpi30Eh"},"source":["Let's plot these poses to see how our vechicle moves.\n","\n","Screenshot this for your reflection."]},{"cell_type":"code","metadata":{"id":"G1C0nQbkBJvR","colab":{"base_uri":"https://localhost:8080/","height":542,"output_embedded_package_id":"1_sYAe48PPjyccMTPHaflWGi-2yOS7Z5O"},"executionInfo":{"status":"ok","timestamp":1587335767091,"user_tz":240,"elapsed":2858,"user":{"displayName":"Collin Avidano","photoUrl":"","userId":"02884380186597284052"}},"outputId":"ddfc4ab0-1b39-4d6f-a3e7-4a1d9d882c42"},"source":["poses_cloud = np.array([[], [], []])\n","for i in range(len(clouds)):\n","    poses_cloud = np.hstack([poses_cloud, np.array([[result.atPose3(i).x()], [result.atPose3(i).y()], [result.atPose3(i).z()]])])\n","\n","init_car_pose = gtsam.Pose3(gtsam.Rot3(0.9982740, -0.0572837,  0.0129474, 0.0575611,  0.9980955, -0.0221840, -0.0116519,  0.0228910,  0.9996701),\n","                            gtsam.Point3(-263.9464864482589, 2467.3015467381383, -19.374652610889633))\n","visualize_clouds([poses_cloud, transform_cloud(init_car_pose, clouds[0])], show_grid_lines=True)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"TrCCt-T3rDtF"},"source":["These unit tests will verify the basic functionality of the function you've implemented in this section. Keep in mind that these are not exhaustive."]},{"cell_type":"code","metadata":{"id":"ce1LpA3_rInm","colab":{"base_uri":"https://localhost:8080/","height":181},"executionInfo":{"status":"ok","timestamp":1587326345499,"user_tz":240,"elapsed":68613,"user":{"displayName":"Collin Avidano","photoUrl":"","userId":"02884380186597284052"}},"outputId":"a8973cc8-4cbb-4360-b0ee-afe4765f487a"},"source":["import unittest\n","\n","class TestFactorGraph(unittest.TestCase):\n","\n","    def setUp(cls):\n","      test_clouds = read_ply(*scans_fnames)[:6]\n","      PRIOR_NOISE = gtsam.noiseModel_Diagonal.Sigmas(np.array([1e-6, 1e-6, 1e-6, 1e-4, 1e-4, 1e-4]))\n","      ICP_NOISE = gtsam.noiseModel_Diagonal.Sigmas(np.array([1e-6, 1e-6, 1e-6, 1e-4, 1e-4, 1e-4]))\n","      test_graph = gtsam.NonlinearFactorGraph()\n","      test_initial_estimates = gtsam.Values()\n","      initial_pose = gtsam.Pose3(gtsam.Rot3(0.9982740, -0.0572837,  0.0129474, 0.0575611,  0.9980955, -0.0221840, -0.0116519,  0.0228910,  0.9996701),\n","                          gtsam.Point3(-263.9464864482589, 2467.3015467381383, -19.374652610889633))\n","      test_graph.add(gtsam.PriorFactorPose3(0, initial_pose, PRIOR_NOISE))\n","      test_initial_estimates.insert(0, initial_pose)\n","      test_graph, test_initial_estimates = populate_factor_graph(test_graph, test_initial_estimates, initial_pose, test_clouds)\n","      cls.graph = test_graph\n","      cls.initial_estimates = test_initial_estimates\n","    \n","    def test_graph_params(self):\n","      self.assertTrue(type(self.graph) == gtsam.NonlinearFactorGraph)\n","    \n","    def test_initial_estimates_params(self):\n","      self.assertTrue(type(self.initial_estimates) == gtsam.Values)\n","\n","def suite():\n","  functions = ['test_graph_params', 'test_initial_estimates_params']\n","  suite = unittest.TestSuite()\n","  for func in functions:\n","    suite.addTest(TestFactorGraph(func))\n","  return suite\n","    \n","if __name__ == \"__main__\":\n","    runner = unittest.TextTestRunner()\n","    runner.run(suite())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["......"],"name":"stdout"},{"output_type":"stream","text":["."],"name":"stderr"},{"output_type":"stream","text":[".\n"," Done\n","......"],"name":"stdout"},{"output_type":"stream","text":["."],"name":"stderr"},{"output_type":"stream","text":[".\n"," Done\n"],"name":"stdout"},{"output_type":"stream","text":["\n","----------------------------------------------------------------------\n","Ran 2 tests in 68.311s\n","\n","OK\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"nqsRcwJFb-DC"},"source":["# Mapping\n","\n","In this section, we'll tackle the mapping component of SLAM (Simulataneous Localization and Mapping). The previous section used a factor graph to localize our vehicle's poses in world coordinates. We'll now use those poses to form a map of the street from the point clouds.\n","\n","Given the poses and the clouds, this task is easy. We'll use your `transform_cloud` method from the ICP section to transform every other cloud in our dataset to be centered at the corresponding pose where the cloud was captured. Visualizing all of these clouds yields the complete map. We don't use every cloud in our dataset to reduce the amount of noise in our map while retaining plenty of detail.\n","\n","Screenshot this for your reflection."]},{"cell_type":"code","metadata":{"id":"Vt8LidY8cARN","colab":{"base_uri":"https://localhost:8080/","height":542,"output_embedded_package_id":"1Z5X8xCFtfbA57zxZlZojtvHj2NExHRS8"},"executionInfo":{"status":"ok","timestamp":1587335981931,"user_tz":240,"elapsed":11627,"user":{"displayName":"Collin Avidano","photoUrl":"","userId":"02884380186597284052"}},"outputId":"2510999c-83b6-4ac8-e3de-e633dd03b690"},"source":["cloud_map = []\n","for i in range(0, len(clouds), 2):\n","    cloud_map.append(transform_cloud(result.atPose3(i), clouds[i-1]))\n","\n","visualize_clouds(cloud_map, show_grid_lines=True, single_color=\"#C6C6C6\")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"7HLLS3R3KsUk"},"source":["# Reflection\n","\n","Complete the reflection questions in the proj6_report_template.pptx, which you can find in the files tab on Canvas. Failure to follow the format will be penalized. Save the report as a .pdf and rename it to \"FIRSTNAME_LASTNAME_reflection.pdf\".\n","\n","### Rubric\n","\n"," * 25 points: ICP Section\n"," * 25 points: Factor Graph Section\n"," * 0 points: Mapping Section (questions in reflection)\n"," * 50 points: Reflection\n","\n","### Submission Details\n","\n","Deliverables are a zip file named \"FIRSTNAME_LASTNAME_project6.zip\" with the following files:\n","\n"," * project6.py - exported from Google Colab\n"," * FIRSTNAME_LASTNAME_reflection.pdf - exported from the given powerpoint\n","\n","This is an individual assignment, everyone should submit their own files.\n","\n"]}]}